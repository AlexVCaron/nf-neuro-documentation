---
title: "Tutorial: steps 3 to 4"
description: Learn how to build a simple pipeline using nf-neuro components
---

import RunIcon from '~icons/codicon/run-all';
import CommandOutputs from '../../../components/CommandOutputs.astro';
import { Steps } from '@astrojs/starlight/components';
import { Tabs, TabItem } from '@astrojs/starlight/components';
import { FileTree } from '@astrojs/starlight/components';
import { Code } from '@astrojs/starlight/components';
import { Card } from '@astrojs/starlight/components';
import Runtime from "@mdx-js/runtime";

:::tip[What to expect from this walkthrough]
In this tutorial, you'll learn how to create a basic pipeline workflow, using components from `nf-neuro`. 

By following steps 1 to 2, you will learn to import and configure a nf-neuro module.
:::

## Step 3: Using and Configuring an nf-neuro Module

In this step, we'll add a `nf-neuro` module for processing DWI images, 
and use a pre-installed module to computes diffusion tensor imaging (DTI) metrics.

To do this, we will go through 4 successive sub-steps:

<Steps>

1. Include the module in the `main.nf` workflow.

2. Use the module in the workflow 

3. Understand input data specific to the module.

4. Configure module parameters in `nextflow.config` using **API Documentation**.
</Steps>


### 1. Include the module 

Modify your **main.nf** file and insert the `include {}` command at the top. This line adds
the module **RECONST_DTIMETRICS** to your project.

<Tabs>
  <TabItem label="Before">
    ```nextflow
    #!/usr/bin/env nextflow

        
    ```
   </TabItem>
  <TabItem label="After">
    ```nextflow
    #!/usr/bin/env nextflow

    include { RECONST_DTIMETRICS } from './modules/nf-neuro/reconst/dtimetrics/main'
    ```
  </TabItem>
</Tabs>

### 2. Use the module in the workflow 

After importing the module, you can then use it in your workflow as follows:

<Tabs>
  <TabItem label="Before">
    ```nextflow
    workflow {
        // ** Now call your input workflow to fetch your files ** //
        data = get_data()
        data.dwi.view() // Contains your DWI data: [meta, dwi, bval, bvec]
    }        
    ```
   </TabItem>
  <TabItem label="After">
    ```nextflow
    workflow {
        // ** Now call your input workflow to fetch your files ** //
        data = get_data()
        RECONST_DTIMETRICS( data.dwi )
    }
    ```
  </TabItem>
</Tabs>

### 3. Understand input data specific to the module.

Before using the `RECONST_DTIMETRICS` module, it's essential to understand the file types it expects as input. 
For this, please refer to the API Documentation: [RECONST_DTIMETRICS](https://scilus.github.io/nf-neuro/api/modules/reconst/dtimetrics/)  

The `Inputs` section module shows that 4 input files are required (excluding meta):

**Mandatory**: DWI, BVAL, BVEC  
**Optionnel** : Mask 

:::caution
`meta` is a special variable, defined in every **module**, a map that gets passed around with the data, into which you can
put information. Beware however, as it is also used to **join channels together** by looking at there whole content.
:::

:::note
Another way to get quick help on how a module works is to use the `nf-core modules info category/tool` 
command. This displays the module's command-line documentation. 
Be careful, though: you won't have access to the module's parameters or default values.
:::

We're now going to prepare the input data using Nextflow's **channel operators** `map()`. 
In our case, the channel `inputs` already contains the data **dwi**, **bval** and **bvec**. 
Since the mask is optional, we can handle it by appending an **empty list**.

<Tabs>
  <TabItem label="Before">
    ```nextflow
    workflow {
        // ** Now call your input workflow to fetch your files ** //
        data = get_data()
        RECONST_DTIMETRICS( data.dwi )
    }   
    ```
   </TabItem>
  <TabItem label="After">
    ```nextflow
    workflow {
        // ** Now call your input workflow to fetch your files ** //
        data = get_data()
        input_dti_metric = data.dwi.map{ it + [[]] }
        RECONST_DTIMETRICS( input_dti_metric )
    }
    ```
  </TabItem>
</Tabs>


:::tip[Let's break down these changes]
`.map{ it + [[]] }`: Adds an empty list ([]) to each input tuple.

`it` refers to the current item being processed and `+ [[]]` is appending an empty list `[]`
wrapped in another list `[[]]` to each item.

This ensures compatibility with the module, even if the mask is not provided.
:::

:::note
Nextflow does not directly support optional entries for processes or modules. 
Providing an empty list ([]) instead of a file as a module input is a workaround for this 
limitation; and indicates that an optional input is not provided.
:::


### 4. Validate Input Data 

To ensure that the new `input_dti_metric` channel is correctly structured,
comment the module (using `//`) and use the [`.view()`](https://www.nextflow.io/docs/latest/reference/operator.html#view)
operator, which will display the results directly in the **terminal**, very useful for **debugging**.

<Tabs>
  <TabItem label="Before">
    ```nextflow
    workflow {
        // ** Now call your input workflow to fetch your files ** //
        data = get_data()
        input_dti_metric = data.dwi.map{ it + [[]] }
        RECONST_DTIMETRICS( input_dti_metric )
    } 
    ```
   </TabItem>
  <TabItem label="After">
    ```nextflow
    workflow {
        // ** Now call your input workflow to fetch your files ** //
        data = get_data()
        input_dti_metric = data.dwi.map{ it + [[]] }
        input_dti_metric.view()
        //RECONST_DTIMETRICS( input_dti_metric )
    }
    ```
  </TabItem>
</Tabs>

<RunIcon class="inline-icon text-blue-300" aria-hidden /> **Now, you can run nextflow..**

   <CommandOutputs>
   <span slot="command">
    ```bash
    nextflow run main.nf --input data -profile docker
    ```
   </span>
   <span slot="output">
    ```bash
    [[id:sub-003_ses-01], /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.nii.gz, /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.bval, /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.bvec, []]
    ```
   </span>
   </CommandOutputs>

You have now configured and checked that the inputs respects the **RECONST_DTIMETRICS** module's expectations, 
taking into account the management of an optional file. The next step is to configure the module parameters.


### 5. Configuring the Module

#### Define module parameters

Each module may require specific parameters. 
To find the required **parameters** and their **default values**, check the `Arguments` section of the module supplied by 
API Documentation [here](https://scilus.github.io/nf-neuro/api/modules/reconst/dtimetrics/) .

In the nextflow.config, you will have to set these parameters using the **process selector** (`withName`) that
links the `ext.` parameter to the `params.` parameter.

```nextflow
process {
    withName: 'YOUR_MODULE' {
        ext.option1 = params.option1
        ext.args1 = boolean/value/str
    }
}
```
:::note
`process { ... }`: This block is used to define default process settings that will apply to all 
                    processes and module in the pipeline unless overridden.
:::

The `RECONST_DTIMETRICS` module requires a set of parameters to be added to the 
`nextflow.config`. Please copy paste it into your nextflow.config after the `manifest` part.

```
process {
    withName: "RECONST_DTIMETRICS" {
        ext.ad = false
        ext.evecs = false
        ext.evals = false
        ext.fa = true
        ext.ga = false
        ext.rgb = false
        ext.md = true
        ext.mode = false
        ext.norm = false
        ext.rd = false
        ext.tensor = false
        ext.nonphysical = false
        ext.pulsation = false
        ext.residual = false
        ext.b0_thr_extract_b0 = 10
        ext.dwi_shell_tolerance = 50
        ext.max_dti_shell_value = 1200
        ext.run_qc = false
    }
}
```
:::note
Here, only FA and MD outputs are enabled (`true`) for efficiency.
:::

#### Fetching outputs from the modules

Last but not least, you now have a working `main.nf` file. You could run the pipeline, 
but the output would be hard to access. To ensure easy access to results, define an 
output directory in `nextflow.config` using the `publishDir`:

<Tabs>
    <TabItem label="Before">
    ```nextflow
    process {
        withName: "RECONST_DTIMETRICS" {
    ```
    </TabItem>
    <TabItem label="After">
    ```nextflow
    process {
        publishDir = { "${params.output}/$meta.id/${task.process.replaceAll(':', '-')}" }
        withName: "RECONST_DTIMETRICS" {
    ```
    </TabItem>
</Tabs>

:::tip[Let's break down these changes]
`publishDir = { "${params.output}/$meta.id/${task.process.replaceAll(':', '-')}" }`


        1. `publishDir` is a tools that dynamically generates the output directory path.

            `${params.output}`: This refers to a parameter called output that should be defined 
                    elsewhere in the pipeline, likely in a params section or passed as a command-line argument. 
                    It serves as the base output directory.

        2. `$meta.id` : Subject/session ID for structured output.

            This suggests that processes are expected to receive a meta object as input, 
            which has an id field. This could be used to create subdirectories for each sample or dataset.

        3. `${task.process.replaceAll(':', '-')}` : Ensures valid directory names.

            This uses the name of the current process (`task.process`) but replaces any colons : with hyphens `-`. 
            This is likely done because colons are not valid characters in directory names on many file systems.
:::

That's it! Your `nextflow.config` should look something like this:

```
profiles {
    docker {
        docker.enabled          = true
        conda.enabled           = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
        docker.runOptions       = '-u $(id -u):$(id -g)'
    }
}

manifest {
    name            = 'scilus/nf-neuro-tutorial'
    description     = """nf-neuro-tutorial is a Nextflow pipeline for processing neuroimaging data."""
    version         = '0.1dev'
}

params.input      = false
params.output     = 'result'

process {

    publishDir = { "${params.output}/$meta.id/${task.process.replaceAll(':', '-')}" }

    withName: "RECONST_DTIMETRICS" {
        ext.ad = false
        ext.evecs = false
        ext.evals = false
        ext.fa = true
        ext.ga = false
        ext.rgb = false
        ext.md = true
        ext.mode = false
        ext.norm = false
        ext.rd = false
        ext.tensor = false
        ext.nonphysical = false
        ext.pulsation = false
        ext.residual = false
        ext.b0_thr_extract_b0 = 10
        ext.dwi_shell_tolerance = 50
        ext.max_dti_shell_value = 1200
        ext.run_qc = false
    }
}
```

You can now uncomment the `RECONST_DTIMETRICS` module in `main.nf` 
and run the pipeline using the following command:

   <CommandOutputs>
   <span slot="command">
    ```bash
    nextflow run main.nf --input data -profile docker
    ```
   </span>
   <span slot="output">
   You should see this output:
        ```
            executor >  local (1)
            executor >  local (1)
            [work_folder_id/id_subfloder] process > RECONST_DTIMETRICS (sub-003_ses-01) [100%] 1 of 1 ✔

            Completed at: Date hour
            Duration    : Xm Ys
            CPU hours   : (a few seconds)
            Succeeded   : 1
        ```
        :::note
        Depending on whether or not you have commented `input_dti_metric.view()`, you will also see the list of files.
        :::
   </span>
   </CommandOutputs>


### 5. Visualize data in result folder

You can check the module's output files with the following command, 
or use the VSCode interface to display FA and MD images via the NiiVue extension (pre-installed).

   <CommandOutputs>
   <span slot="command">
    ```bash
        ls ./result/sub-003_ses-01/RECONST_DTIMETRICS/
    ```
   </span>
   <span slot="output">
   You should see this output:
        ```
        sub-003_ses-01__fa.nii.gz  sub-003_ses-01__md.nii.gz  versions.yml
        ```
   </span>
   </CommandOutputs>



## Step 4: Install and Use a New nf-neuro Module

### List Available Modules

Use the nf-core modules list command to check available modules. 
It supports remote (for online repositories) and local (for installed modules).
You can filter modules using `category` name (bundle, denoising, reconst, ...).
To list all modules available on nf-neuro/modules, you can use `nf-core modules list remote`, 
which will print all available modules to the terminal.

   <CommandOutputs>
   <span slot="command">
    ```bash
       # List all modules
       nf-core modules list remote

       # List only reconst modules
       nf-core modules list remote reconst
    ```
   </span>
   <span slot="output">

        ```

        INFO     Modules available from https://github.com/scilus/nf-neuro.git (main):                                                                                                 
                                                                                                                                                                                    
        ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
        ┃ Module Name                      ┃
        ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
        │ betcrop/antsbet                  │
        │ betcrop/fslbetcrop               │
        │ betcrop/synthbet                 │
        │ bundle/centroid                  │
        │ bundle/coloring                  │
        │ bundle/fixelafd                  │
        │ bundle/labelmap                  │
        │ bundle/recognize                 │
        │ bundle/stats                     │
        │ bundle/uniformize                │
        │ connectivity/afdfixel            │
        │ connectivity/decompose           │
        │ connectivity/visualize           │
        │ denoising/mppca                  │
        │ denoising/nlmeans                │
        │ image/applymask                  │
        │ image/burnvoxels                 │
        │ image/convert                    │
        │ image/cropvolume                 │
        │ image/powderaverage              │
        │ image/resample                   │
        │ io/nii2dcm                       │
        │ io/readbids                      │
        │ preproc/eddy                     │
        │ preproc/gibbs                    │
        │ preproc/n4                       │
        │ preproc/normalize                │
        │ preproc/topup                    │
        │ reconst/diffusivitypriors        │
        │ reconst/dtimetrics               │
        │ reconst/fodf                     │
        │ reconst/freewater                │
        │ reconst/frf                      │
        │ reconst/ihmt                     │
        │ reconst/meanfrf                  │
        │ reconst/noddi                    │
        │ reconst/shmetrics                │
        │ reconst/shsignal                 │
        │ registration/anattodwi           │
        │ registration/ants                │
        │ registration/antsapplytransforms │
        │ registration/convert             │
        │ registration/easyreg             │
        │ registration/synthregistration   │
        │ registration/tractogram          │
        │ segmentation/fastseg             │
        │ segmentation/fastsurfer          │
        │ segmentation/freesurferseg       │
        │ segmentation/fsreconall          │
        │ segmentation/synthseg            │
        │ stats/metricsinroi               │
        │ tracking/localtracking           │
        │ tracking/pfttracking             │
        │ tractogram/densitymap            │
        │ tractogram/removeinvalid         │
        │ tractogram/resample              │
        │ utils/extractb0                  │
        └──────────────────────────────────┘
        ```
   </span>
   </CommandOutputs>


:::note
On a first run of the commands, you may get prompted to configure some aspects of `nf-core`. You can accept every
prompt you see.
:::

:::caution
If you get an error saying `nf-core` command doesn't exists, then `poetry` has failed to load in the terminal
correctly. First, close your terminal, open a new one and try again. If the tool still cannot be found, try the
command `poetry shell`, then running `nf-core modules install` again. If this does not solve the problem, [open an
issue](https://github.com/scilus/nf-neuro/issues/new?template=bug_report.md) on the `nf-neuro` repository.
:::

### Install a new module

Now, you can install the modules you want to include in your pipeline. 
Let's install the `denoising/nlmeans` module for DWI denoising. 
You can install modules using `nf-core modules install` command.
The new module will be installed to the `./modules/nf-neuro/modules/` directory.


   <CommandOutputs>
   <span slot="command">
    ```bash
        nf-core modules install denoising/nlmeans
    ```
   </span>
   <span slot="output">
   You should see this output:
    ```
                                          ,--./,-.
          ___     __   __   __   ___     /,-._.--~\
    |\ | |__  __ /  ` /  \ |__) |__         }  {
    | \| |       \__, \__/ |  \ |___     \`-._,-`-,
                                          `._,._,'

    nf-core/tools version 2.14.1 - https://nf-co.re
    There is a new version of nf-core/tools available! (3.2.0)


    INFO     Installing 'denoising/nlmeans'                                                                                                                                        
    INFO     Use the following statement to include this module:                                                                                                                   
                                                                                                                                                                                
    include { DENOISING_NLMEANS } from '../modules/nf-neuro/denoising/nlmeans/main'  
    ```

    :::note
    By default nf-core prints the include command with a `../modules/[...]`.
    In this tutorial, you need to delete a directory, like this `./modules/[...]`.
    :::
   </span>
   </CommandOutputs>

### Configure and Use the Module

The purpose of adding this module is to denoise the DWI image before computing the DTI metrics.
To do this, simply repeat the sequence of sub-steps seen in 
**Step 3: How to use and configure an nf-neuro module in the workflow**.

<Steps>

1. Include the module in `main.nf`.

2. Bind the module in your `workflow`.

3. Prepare the input data structure for denoising module.

    Unlike the DTI module, where input data can be provided directly, 
    the MPPCA denoising module requires only the DWI image and an optional mask.

    The challenge is to leverage NextFlow tools to restructure the input data, 
    making it easier to handle. The goal is to efficiently retrieve specific files, 
    such as the DWI image or the BVEC and BVAL files. 
    To achieve this, we'll use NextFlow's [multiMap](https://www.nextflow.io/docs/latest/reference/operator.html#multimap)
    operator to generate multiple output channels from a single input channel, as shown below.

    <Tabs>
    <TabItem label="Command to add">
    ```nextflow
    ch_dwi_bvalbvec = inputs.dwi
        .multiMap { meta, dwi, bval, bvec ->
            dwi:            [ meta, dwi ]
            bvs_files:      [ meta, bval, bvec ]
            dwi_bval_bvec:  [ meta, dwi, bval, bvec ]
        }
    ```
    </TabItem>
    <TabItem label="Let's break it down">
    <Steps>

    1. `inputs.dwi` is the input channel from `get_data` containing : meta, dwi, bval, and bvec.

    2. The [multiMap](https://www.nextflow.io/docs/latest/reference/operator.html#multimap) : creates three new entries in different output channels:

            a. dwi: This output contains the meta information and the dwi file. 
            
            b. bvs_files: This output contains the meta information, bval file, and bvec file. 
            
            c. dwi_bval_bvec: This output contains all four elements from the input.

    3. ch_dwi_bvalbvec : Allows easy access to different file groups
    
        The result of this operation is a multi-channel object, and you can access these channels as follows:

            ch_dwi_bvalbvec.dwi : [meta, dwi]

            ch_dwi_bvalbvec.bvs_files : [meta, bval, bvec]

            ch_dwi_bvalbvec.dwi_bval_bvec : [meta, dwi, bval, bvec]

    </Steps>

    </TabItem>
    </Tabs>

    :::note
    Why Use `multiMap`?

    This approach is useful in Nextflow workflows when different processes require distinct subsets or 
    different combinations of your input data.
    With `multiMap`, you can also efficiently provide the right data to each process without duplicating it in your workflow.

    As in this tutorial, you might have one process that only needs the dwi file, another that needs the bval 
    and bvec files, and a third that needs all of them. 

4. Configure the denosing module in the `nextflow.config` using API Documentation [here](https://scilus.github.io/nf-neuro/api/modules/denoising/mppca/)

5. Adapt the input for `RECONST_DTIMETRICS` module to integrate denoised DWI.

    <Tabs>
    <TabItem label="Command to add in workflow">
    ```nextflow
    // Add this command just after the DENOISING_MPPCA module
    ch_dwi_denoised = DENOISING_MPPCA.out.image

    // You can now reuse the outputs and supply them to another module!
    // Update the input for RECONST_DTIMETRICS with DWI denoised output
    input_dti_denoised = ch_dwi_denoised
            .join(ch_dwi_bvalbvec.bvs_files)
            .map{ it + [[]] }

    // Update input name
    RECONST_DTIMETRICS( input_dti_denoised )
    ```
    </TabItem>
    <TabItem label="Let's break it down">
    <Steps>

    1. `DENOISING_MPPCA.out.image` : stores the denoised output.
      
        Assign the output from DENOISING_MPPCA to a new channel named `ch_dwi_denoised`. 
        Specifically, it's taking the `image` output.

        The **name** of a module's **output(s)** can be determined via the API Documentation in the `Outputs` section.

    2. `.join(ch_dwi_bvalbvec.bvs_files)`: merges it with BVAL/BVEC data
    
        The [join](https://www.nextflow.io/docs/latest/reference/operator.html#join)
        operator is used here to combine the items from `ch_dwi_denoised` with items from another channel `ch_dwi_bvalbvec.bvs_files`.
        The join operation matches items from both channels based on a common key (by default, the first element of each item).

    3. `.map{ it + [[]] }`:  Adds an empty list ([]) to each input tuple.
    
        After joining, we use map to transforms each item in the channel, and adding an empty list [[]], 
        for the optional mask input. The map operation is similar to the one we did for the DTI module in **Step 2**.

    </Steps>

    </TabItem>
    </Tabs>



6. Run and Verify the Pipeline : 

    <Tabs>
    <TabItem label="Check if it works">

    ```bash
    nextflow run main.nf --input data -profile docker
    ```
    </TabItem>
    <TabItem label="Expected output">

    ```bash
    N E X T F L O W   ~  version 24.10.4

    Launching `main.nf` [astonishing_borg] DSL2 - revision: d69b63f305

    executor >  local (2)
    [ec/62dd72] process > DENOISING_MPPCA (sub-003_ses-01)    [100%] 1 of 1 ✔
    [6e/837a31] process > RECONST_DTIMETRICS (sub-003_ses-01) [100%] 1 of 1 ✔
    Completed at: Date Hour
    Duration    : 1m 19s
    CPU hours   : (a few seconds)
    Succeeded   : 2
    ```

    Check your resulting images in the results folder!

    </TabItem>
    <TabItem label="Expected main.nf">
    ```nextflow
    #!/usr/bin/env nextflow

    include { RECONST_DTIMETRICS } from './modules/nf-neuro/reconst/dtimetrics/main'
    include { DENOISING_MPPCA } from './modules/nf-neuro/denoising/mppca/main'

    workflow get_data {
        main:
            if ( !params.input ) {
                log.info "You must provide an input directory containing all images using:"
                log.info ""
                log.info "    --input=/path/to/[input]   Input directory containing your subjects"
                log.info "                        |"
                log.info "                        ├-- S1"
                log.info "                        |    └-- ses-01"
                log.info "                        |    |    ├-- anat"
                log.info "                        |    |    |   |--*t1.nii.gz"
                log.info "                        |    |    |--dwi"
                log.info "                        |    |    |   |--*dwi.nii.gz"
                log.info "                        |    |    |   ├-- *dwi.bval"
                log.info "                        |    |    |   └-- *dwi.bvec"
                log.info "                        |    └-- ses-02"            
                log.info "                        └-- S2"
                log.info "                             └-- ses-01"
                log.info "                             |     ├-- anat"
                log.info "                             |    |   |--*t1.nii.gz"
                log.info "                             |    |--dwi"
                log.info "                             |    |   |--*dwi.nii.gz"
                log.info "                             |    |   ├-- *dwi.bval"
                log.info "                             |    |   └-- *dwi.bvec"
                log.info "                             └-- ses-02" 
                log.info ""
                error "Please resubmit your command with the previous file structure."
            }

            input = file(params.input)
            // ** Loading all files. ** //
            dwi_channel = Channel.fromFilePairs("$input/**/**/dwi/*dwi.{nii.gz,bval,bvec}", size: 3, flat: true)
                { it.parent.parent.parent.name + "_" + it.parent.parent.name}
                .map{ sid, bvals, bvecs, dwi -> [ [id: sid], dwi, bvals, bvecs ] }
        emit:
            dwi = dwi_channel
    }

    workflow {
        inputs = get_data()

        // Use Multimap to split the tuple into multi inputs structure
        ch_dwi_bvalbvec = inputs.dwi
            .multiMap { meta, dwi, bval, bvec ->
                dwi:            [ meta, dwi ]
                bvs_files:      [ meta, bval, bvec ]
                dwi_bval_bvec:  [ meta, dwi, bval, bvec ]
            }

        // Denoising DWI
        input_dwi_denoise = ch_dwi_bvalbvec.dwi
                        .map{ it + [[]] }

        DENOISING_MPPCA( input_dwi_denoise )

        // Fetch specific output
        ch_dwi_denoised = DENOISING_MPPCA.out.image

        // Input DTI update with DWI denoised output
        input_dti_denoised = ch_dwi_denoised
                .join(ch_dwi_bvalbvec.bvs_files)
                .map{ it + [[]] }

        RECONST_DTIMETRICS( input_dti_denoised )

    }
    ```

    </TabItem>
    <TabItem label="Expected nextflow.config">
    ```nextflow
    profiles {
        docker {
            docker.enabled          = true
            conda.enabled           = false
            singularity.enabled     = false
            podman.enabled          = false
            shifter.enabled         = false
            charliecloud.enabled    = false
            apptainer.enabled       = false
            docker.runOptions       = '-u $(id -u):$(id -g)'
        }
    }

    manifest {
        name            = 'scilus/nf-neuro-tutorial'
        description     = """nf-neuro-tutorial is a Nextflow pipeline for processing neuroimaging data."""
        version         = '0.1dev'
    }

    params.input      = false
    params.output     = 'result'

    process {

        publishDir = { "${params.output}/$meta.id/${task.process.replaceAll(':', '-')}" }

        withName: "DENOISING_MPPCA" {
            ext.extent = 3
        }

        withName: "RECONST_DTIMETRICS" {
            ext.ad = false
            ext.evecs = false
            ext.evals = false
            ext.fa = true
            ext.ga = false
            ext.rgb = false
            ext.md = true
            ext.mode = false
            ext.norm = false
            ext.rd = false
            ext.tensor = false
            ext.nonphysical = false
            ext.pulsation = false
            ext.residual = false
            ext.b0_thr_extract_b0 = 10
            ext.dwi_shell_tolerance = 50
            ext.max_dti_shell_value = 1200
            ext.run_qc = false
        }
    }
    ```
    </TabItem>
    </Tabs>


</Steps>