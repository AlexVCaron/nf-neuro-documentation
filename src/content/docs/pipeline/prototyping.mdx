---
title: Tutoriel to create your pipeline using components from nf-neuro
description: Learn how to build a simple pipeline using nf-neuro components
---

import CommandOutputs from '../../../components/CommandOutputs.astro';
import { Steps } from '@astrojs/starlight/components';
import { Tabs, TabItem } from '@astrojs/starlight/components';

# Welcome to the nf-neuro tutorial!

In this tutorial, you'll learn how to setup your pipeline environment and create a basic
pipeline workflow, using components from `nf-neuro`. 

The material to follow the tutorial is available [here](https://github.com/scilus/nf-neuro-tutorial).
To follow along, clone the tutorial repository:

```bash
git clone git@github.com:yourgithubID/nf-neuro-tutorial.git
cd nf-neuro-tutorial
```

# Environment Setup

We recommend using **VS Code** and the `development container`. Follow the
[setup documentation](/nf-neuro/custom-pipeline/setup) or
[manual installation instructions](/nf-neuro/custom-pipeline/setup#manual-installation) to setup yourself manually.

# Tutorial overview

In this tutorial you will create a simple pipeline using `nf-neuro` components to process a 
diffusion-weighted image (DWI) and T1-weighted (T1w) images and extracting mean diffusivity  
(MD) and fractional anisotropy (FA) values from white matter (WM), gray matter (GM), 
and cerebrospinal fluid (CSF) maps.

### Folder structure 

The tutorial folder is pre-configured with necessary files and directories.
The **config**, **tests**, **modules** and **subworkflows** folders contain the pre-installed nf-neuro components, 
while the **data** folder contains the data provided for the tutorial.

```
nf-neuro-tutorial
              |
              ├-- .devcontainer
              ├-- config
              ├-- data
              ├-- modules              
              ├-- subworkflows
              ├-- tests
              ├-- .gitignore
              ├-- .nf-core.yml
              ├-- README.md
              ├-- main.nf
              ├-- modules.json
              ├-- nextflow.config
              └-- nf-test.config
```

### `nextflow.config`

The `nextflow.config` file defines execution parameters and default configurations.
It also contains **parameters** that users can change when calling your pipeline
(prefixed with `params.`). Here is an example of a basic `nextflow.config` file :

```nextflow
profiles {
    docker {
        docker.enabled          = true
        conda.enabled           = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
        docker.runOptions       = '-u $(id -u):$(id -g)'
    }
}

manifest {
    name            = 'scilus/nf-neuro-tutorial'
    description     = """nf-neuro-tutorial is a Nextflow pipeline for processing neuroimaging data."""
    version         = '0.1dev'
}
```

The parameters defined with `params.` can be changed at execution by another `nextflow.config` file or
by supplying them as arguments when calling the pipeline using `nextflow run` :

```bash
nextflow run main.nf --input /path/to/input --output /path/to/output
```

:::caution
If using a version of `nextflow` prior to `22.03.0-edge` (or `22.04.0` if using only stable releases),
you need to add `-dsl2` to the `nextflow run` command to enable the DSL2 syntax in which your
pipeline and `nf-neuro` are written.
:::


### `main.nf`

This file is your pipeline execution file. It contains all modules and subworkflows you want to run, and the
channels that define how data passes between them. This is also where you define how to fetch your input pipeline files.
This can be done using a workflow definition called `get_data`. Here is an example for a basic usage:

```nextflow
#!/usr/bin/env nextflow

workflow get_data {
    main:
        if ( !params.input ) {
            log.info "You must provide an input directory containing all files using:"
            log.info ""
            log.info "    --input=/path/to/[input]   Input directory containing the file needed"
            log.info "                        |"
            log.info "                        └-- Input"
            log.info "                             └-- participants.*"
            log.info ""
            error "Please resubmit your command with the previous file structure."
        }

        input = file(params.input)
        // ** Loading all files. ** //
        participants_channel = Channel.fromFilePairs("$input/participants.*", flat: true)
            { "participants_files" }

    emit:
        participants = participants_channel
}

workflow {
    // ** Now call your input workflow to fetch your files ** //
    data = get_data()
    data.participants.view()
}
```

### Data

To keep things simple, we'll consider you want to process a dataset that contains for one 
subject and session a DWI and a T1 image, as follows :

```bash
data
    |--dataset_description.json
    |--participants.json
    |--participants.tsv
    └-- sub-003
        └-- ses-01
            |-- anat
            |   |-- sub-003_ses-01_T1w.json
            |   |-- sub-003_ses-01_T1w.nii.gz
            └-- dwi
                |-- sub-003_ses-01_dir-AP_dwi.bval
                |-- sub-003_ses-01_dir-AP_dwi.bvec
                |-- sub-003_ses-01_dir-AP_dwi.json
                └-- sub-003_ses-01_dir-AP_dwi.nii.gz
```


# Start to play with the tutorial/Follow the tutorial steps

The tutorial consists of 11 sequential steps, described below, which will enable you to complete 
the pre-filled `main.nf` and `nextflow.config` files to obtain a complete workflow.


## Step 1: Visualize input data

Open the main.nf file in VS Code. This file is pre-filled with a workflow named get_data, 
which is responsible for fetching input files from a specified directory.
This step serves as a generic data-loading process commonly used at the start of a pipeline.

A key concept here is the use of `Channel`, which enables efficient, asynchronous data flow. 
The `fromFilePairs()` method is particularly useful for handling paired-end sequencing data, 
but in this case, it helps group related files.

To run the Nextflow pipeline, use the following command: : 

   <CommandOutputs>
   <span slot="command">
    ```bash
    nextflow run main.nf --input data -profile docker
    ```
   </span>
   <span slot="output">
   You should see this output:

    ```bash
    [participants_files, /workspaces/nf-neuro-tutorial_test/data/participants.json, /workspaces/nf-neuro-tutorial_test/data/participants.tsv]
    ```   
   </span>
   </CommandOutputs>

## Step 2: Create input structure

### Update data structure

Now, let's modify the get_data workflow to fetch the test data. 
Replace the existing get_data workflow with the following and rerun Nextflow.

<Tabs>
<TabItem label="Command">
    ```nextflow
    #!/usr/bin/env nextflow

    workflow get_data {
        main:
            if ( !params.input ) {
                log.info "You must provide an input directory containing all images using:"
                log.info ""
                log.info "    --input=/path/to/[input]   Input directory containing your subjects"
                log.info "                        |"
                log.info "                        ├-- S1"
                log.info "                        |    └-- ses-01"
                log.info "                        |    |    ├-- anat"
                log.info "                        |    |    |   |--*t1.nii.gz"
                log.info "                        |    |    |--dwi"
                log.info "                        |    |    |   |--*dwi.nii.gz"
                log.info "                        |    |    |   ├-- *dwi.bval"
                log.info "                        |    |    |   └-- *dwi.bvec"
                log.info "                        |    └-- ses-02"            
                log.info "                        └-- S2"
                log.info "                             └-- ses-01"
                log.info "                             |     ├-- anat"
                log.info "                             |    |   |--*t1.nii.gz"
                log.info "                             |    |--dwi"
                log.info "                             |    |   |--*dwi.nii.gz"
                log.info "                             |    |   ├-- *dwi.bval"
                log.info "                             |    |   └-- *dwi.bvec"
                log.info "                             └-- ses-02" 
                log.info ""
                error "Please resubmit your command with the previous file structure."
            }

            input = file(params.input)
            // ** Loading all files. ** //
            dwi_channel = Channel.fromFilePairs("$input/**/**/dwi/*dwi.{nii.gz,bval,bvec}", size: 3, flat: true)

        emit:
            dwi = dwi_channel
    }

    workflow {
        // ** Now call your input workflow to fetch your files ** //
        data = get_data()
        data.dwi.view() // Contains your DWI data: [meta, dwi, bval, bvec]
    }
    ```
</TabItem>
<TabItem label="Expected output">
   ```bash    
   [sub-003_ses-01_dir-AP, /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.bval, /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.bvec, /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.nii.gz]
   ```
   Each element in the output channel is a tuple containing:

    - A unique key identifier (subject/session)
    - The matching .nii.gz file (DWI image)
    - The matching .bval file
    - The matching .bvec file

    And following this format : 

    ```bash
    [subject_session_id, /path/to/subject1/ses-01/dwi/*dwi.nii.gz, /path/to/subject1/ses-01/dwi/*dwi.bval, /path/to/subject1/ses-01/dwi/*dwi.bvec]
    ```
</TabItem>
<TabItem label=" Let's break it down">

<Steps>

1. File Matching Pattern

    `$input/**/**/dwi/*dwi.{nii.gz,bval,bvec}`

        This is the glob pattern used to match files. 
        It searches for files in any subdirectory of $input inside dwi/, matching .nii.gz, .bval, or .bvec files.

2. Number of file

    `size`: 3
    
    This option specifies that each emitted item should contain 3 files (in this case, the dwi.nii.gz, .bval, and .bvec files).

3. Format 

    `flat`: true
    
    Flattens the output to emit file groups as tuples rather than nested lists.
</Steps>
</TabItem>
</Tabs>


### Set correctly the Subject and session ID
Now let's modify the input structure to make `sub-003_ses-01_dir-AP` become `sub-003_ses-01` 
using the following structure and `it` :  

   <CommandOutputs>
   <span slot="command">
    ```nextflow
            input = file(params.input)
            // ** Loading all files. ** //
            dwi_channel = Channel.fromFilePairs("$input/**/**/dwi/*dwi.{nii.gz,bval,bvec}", size: 3, flat: true)
                { it.parent.parent.parent.name + "_" + it.parent.parent.name}
    ```
   </span>
   <span slot="output">
   You should see this output:

   ```bash frame="none"      
    [sub-003_ses-01, /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.bval, /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.bvec, /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.nii.gz]
   ```

    Let's explain it step by step:

    `{ it.parent.parent.parent.name + "_" + it.parent.parent.name}`
    
    This is a closure that defines how to create the grouping key for the file pairs. 
    It's using the names of the parent directories to create a unique identifier, 
    so you need to add as many "parent" as necessary to fit your data structure.

    To get subjectID `sub-003` : 

    it
      .parent > `sub-003`
        .parent > `ses-01`
          .parent > `dwi`
            .name > `sub-003_ses-01_dir-AP_dwi.bval`

    To get sessionNumber `ses-01`:

    it
      .parent > `ses-01`
        .parent > `dwi`
          .name > `sub-003_ses-01_dir-AP_dwi.bval`
   </span>
   </CommandOutputs>


### Organizing Data for Processing

By default, files are sorted alphabetically, so you need to reorder them to get a specific file order. 
To do this, you use the `map` function, as follows:

<Tabs>
<TabItem label="Command">
    ```nextflow
           input = file(params.input)
           // ** Loading all files. ** //
           dwi_channel = Channel.fromFilePairs("$input/**/**/dwi/*dwi.{nii.gz,bval,bvec}", size: 3, flat: true)
               { it.parent.parent.parent.name + "_" + it.parent.parent.name}
               .map{ sid, bvals, bvecs, dwi -> [ [id: sid], dwi, bvals, bvecs ] } // Reordering the inputs.
    ```
</TabItem>
<TabItem label="Expected output">
   You should see this output:

   ```bash frame="none"      
    [[id:sub-003_ses-01], /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.nii.gz, /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.bval, /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.bvec]
   ```
</TabItem>
<TabItem label="Let's break it down">

    `.map{ sid, bvals, bvecs, dwi -> [ [id: sid], dwi, bvals, bvecs ] }`

    This is a map operation that reorganizes the emitted data. 
    It takes the sid (sample ID), bvals, bvecs, and dwi files and reorganizes them into a new structure.

    The output is a channel where each element is a tuple containing:

        - [id: sid] corresponds to [id:sub-003_ses-01]
        - dwi corresponds to the dwi.nii.gz file
        - bvals corresponds to the .bval file
        - bvecs corresponds to the .bvec file

</TabItem>
</Tabs>

Now, your input pipeline data is well-structured, facilitating seamless processing in subsequent pipeline stages. 
Each dataset includes a clearly labeled subject ID and session, along with all necessary files for DWI 
processing — such as the DWI file, b-values, and b-vectors.



## Step 3: Using and Configuring an nf-neuro Module

In this step, we'll add an `nf-neuro` module for processing DWI images, 
and use a pre-installed module to Computes diffusion tensor imaging (DTI) metrics
as an example: **RECONST_DTIMETRICS**.
To do this, we will go through 4 successive sub-steps:

<Steps>

1. Include the module in the `main.nf` workflow.

2. Bind the module within the workflow.

3. Prepare input data for the module.

4. Configure module parameters in `nextflow.config` using **API Documentation**.
</Steps>


### Include the module 
To add the module to your project, insert the `include {}` command at the top of the `main.nf` file: 

<Tabs>
<TabItem label="Command to add">
```nextflow 
#!/usr/bin/env nextflow

include { RECONST_DTIMETRICS } from './modules/nf-neuro/reconst/dtimetrics/main'

``` 
</TabItem>
</Tabs>

### Bind the module within the workflow 

After importing the module, bind it to your workflow as follows: 

<Tabs>
<TabItem label="Command to add">
    ```nextflow
        workflow {
            inputs = get_data() // Get the data into the worflow

            RECONST_DTIMETRICS( input_dti_metric )

        }
    ```
</TabItem>
</Tabs>


### Prepare input data for the module 

#### Understanding Required Input(s)

Before using the `RECONST_DTIMETRICS` module, it's essential to understand the file types it expects as input. 
For this, please refer to the API Documentation: [RECONST_DTIMETRICS](https://scilus.github.io/nf-neuro/api/modules/reconst/dtimetrics/)  

The `Inputs` section module shows that 4 input files are required (excluding meta): (add a screenshot ?)

**Mandatory**: DWI, BVAL, BVEC  
**Optionnel** : Mask 

:::caution
`meta` is a special variable, defined in every **module**, a map that gets passed around with the data, into which you can
put information. Beware however, as it is also used to **join channels together** by looking at there whole content.
:::

:::note
Another way to get quick help on how a module works is to use the `nf-core modules info category/tool` 
command. This displays the module's command-line documentation. 
Be careful, though: you won't have access to the module's parameters or default values.
:::

We're now going to prepare the input data using Nextflow's **channel operators** `map()`. 
In our case, the channel `inputs` already contains the data **dwi**, **bval** and **bvec**. 
Since the mask is optional, we can handle it by appending an **empty list**.

<Tabs>
<TabItem label="Command to add">
    ```nextflow
        workflow {
            inputs = get_data()

            input_dti_metric = inputs
                                .map{ it + [[]] }

            RECONST_DTIMETRICS( input_dti_metric )

        }
    ```
</TabItem>
<TabItem label="Let's explain it">

    `.map{ it + [[]] }`: Adds an empty list ([]) to each input tuple.

    `it` refers to the current item being processed and `+ [[]]` is appending an empty list `[]`
    wrapped in another list `[[]]` to each item.

    This ensures compatibility with the module, even if the mask is not provided.

</TabItem>
</Tabs>


:::note
Nextflow does not directly support optional entries for processes or modules. 
Providing an empty list ([]) instead of a file as a module input is a workaround for this 
limitation; and indicates that an optional input is not provided.
:::


#### Validate Input Data 

To ensure that the new `input_dti_metric` channel is correctly correctly structured,
comment the module (using `//`) and use the [`.view()`](https://www.nextflow.io/docs/latest/reference/operator.html#view)
operator, which will display the results directly in the **terminal**, very useful for **debugging**.

   <CommandOutputs>
   <span slot="command">
        ```nextflow
        workflow {
            inputs = get_data()

            input_dti_metric = inputs.map{ it + [[]] }
            input_dti_metric.view()

            //RECONST_DTIMETRICS( input_dti_metric )

        }
        ```
    And run : 
    ```bash
    nextflow run main.nf --input data -profile docker
    ```
   </span>
   <span slot="output">
   You should see this output:
        ```
        [[id:sub-003_ses-01], /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.nii.gz, /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.bval, /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/dwi/sub-003_ses-01_dir-AP_dwi.bvec, []]
        ```
    This confirms that the input data is structured correctly, including the optional mask field.

   </span>
   </CommandOutputs>

You have now configured and checked that the inputs respects the **RECONST_DTIMETRICS** module's expectations, 
taking into account the management of an optional file. The next step is to configure the module parameters.


### Configuring the Module

#### Define module parameters

Each module may require specific parameters. 
To find the required **parameters** and their **default values**, check the `Arguments` section of the module supplied by 
API Documentation [here](https://scilus.github.io/nf-neuro/api/modules/reconst/dtimetrics/) .

To set these parameters, use the **process selector** (`withName`) that
links the `ext.` parameter to the `params.` parameter in nextflow.config:

```nextflow
process {
    withName: 'YOUR_MODULE' {
        ext.option1 = params.option1
        ext.args1 = boolean/value/str
    }
}
```
:::note
`process { ... }`: This block is used to define default process settings that will apply to all 
                    processes and module in the pipeline unless overridden.
:::

The `RECONST_DTIMETRICS` module requires a set of parameters to be added to the 
`nextflow.config` file after `manifest` part, as follows:

```
process {

    withName: "RECONST_DTIMETRICS" {
        ext.ad = false
        ext.evecs = false
        ext.evals = false
        ext.fa = true
        ext.ga = false
        ext.rgb = false
        ext.md = true
        ext.mode = false
        ext.norm = false
        ext.rd = false
        ext.tensor = false
        ext.nonphysical = false
        ext.pulsation = false
        ext.residual = false
        ext.b0_thr_extract_b0 = 10
        ext.dwi_shell_tolerance = 50
        ext.max_dti_shell_value = 1200
        ext.run_qc = false
    }
}
```
:::note
Here, only FA and MD outputs are enabled (`true`) for efficiency.
:::

#### Fetching outputs from the modules

Last but not least, you now have a working `main.nf` file. You could run the pipeline, 
but the output would be hard to access. To ensure easy access to results, define an 
output directory in `nextflow.config` using the `publishDir` :

<Tabs>
<TabItem label="Add to nextflow.config">
    ```nextflow

    params.input      = false
    params.output     = 'result'

    process {
        publishDir = { "${params.output}/$meta.id/${task.process.replaceAll(':', '-')}" }
    }
    ```
</TabItem>
<TabItem label="Let's explain it:">
    <Steps>
        1. `publishDir` is a tools that dynamically generates the output directory path.

            `${params.output}`: This refers to a parameter called output that should be defined 
                    elsewhere in the pipeline, likely in a params section or passed as a command-line argument. 
                    It serves as the base output directory.

        2. `$meta.id` : Subject/session ID for structured output.

            This suggests that processes are expected to receive a meta object as input, 
            which has an id field. This could be used to create subdirectories for each sample or dataset.

        3. `${task.process.replaceAll(':', '-')}` : Ensures valid directory names.

            This uses the name of the current process (`task.process`) but replaces any colons : with hyphens `-`. 
            This is likely done because colons are not valid characters in directory names on many file systems.
    </Steps>
</TabItem>
</Tabs>



That's it! Your `nextflow.config` should look something like this:

```
profiles {
    docker {
        docker.enabled          = true
        conda.enabled           = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
        docker.runOptions       = '-u $(id -u):$(id -g)'
    }
}

manifest {
    name            = 'scilus/nf-neuro-tutorial'
    description     = """nf-neuro-tutorial is a Nextflow pipeline for processing neuroimaging data."""
    version         = '0.1dev'
}

params.input      = false
params.output     = 'result'

process {

    publishDir = { "${params.output}/$meta.id/${task.process.replaceAll(':', '-')}" }

    withName: "RECONST_DTIMETRICS" {
        ext.ad = false
        ext.evecs = false
        ext.evals = false
        ext.fa = true
        ext.ga = false
        ext.rgb = false
        ext.md = true
        ext.mode = false
        ext.norm = false
        ext.rd = false
        ext.tensor = false
        ext.nonphysical = false
        ext.pulsation = false
        ext.residual = false
        ext.b0_thr_extract_b0 = 10
        ext.dwi_shell_tolerance = 50
        ext.max_dti_shell_value = 1200
        ext.run_qc = false
    }
}
```

You can now uncomment the `RECONST_DTIMETRICS` module in `main.nf` 
and run the pipeline using the following command:

   <CommandOutputs>
   <span slot="command">
    ```bash
    nextflow run main.nf --input data -profile docker
    ```
   </span>
   <span slot="output">
   You should see this output:
        ```
            executor >  local (1)
            executor >  local (1)
            [work_folder_id/id_subfloder] process > RECONST_DTIMETRICS (sub-003_ses-01) [100%] 1 of 1 ✔

            Completed at: Date hour
            Duration    : Xm Ys
            CPU hours   : (a few seconds)
            Succeeded   : 1
        ```
        :::note
        Depending on whether or not you have commented `input_dti_metric.view()`, you will also see the list of files.
        :::
   </span>
   </CommandOutputs>


#### Visualize data in result folder

You can check the module's output files with the following command, 
or use the VSCode interface to display FA and MD images via the NiiVue extension (pre-installed).

   <CommandOutputs>
   <span slot="command">
    ```bash
        ls ./result/sub-003_ses-01/RECONST_DTIMETRICS/
    ```
   </span>
   <span slot="output">
   You should see this output:
        ```
        sub-003_ses-01__fa.nii.gz  sub-003_ses-01__md.nii.gz  versions.yml
        ```
   </span>
   </CommandOutputs>



## Step 4: Install and Use a New nf-neuro Module

### List Available Modules

Use the nf-core modules list command to check available modules. 
It supports remote (for online repositories) and local (for installed modules).
You can filter modules using `category` name (bundle, denoising, reconst, ...).
To list all modules available on nf-neuro/modules, you can use `nf-core modules list remote`, 
which will print all available modules to the terminal.

   <CommandOutputs>
   <span slot="command">
    ```bash
       # List all modules
       nf-core modules list remote

       # List only reconst modules
       nf-core modules list remote reconst
    ```
   </span>
   <span slot="output">

        ```

        INFO     Modules available from https://github.com/scilus/nf-neuro.git (main):                                                                                                 
                                                                                                                                                                                    
        ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
        ┃ Module Name                      ┃
        ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
        │ betcrop/antsbet                  │
        │ betcrop/fslbetcrop               │
        │ betcrop/synthbet                 │
        │ bundle/centroid                  │
        │ bundle/coloring                  │
        │ bundle/fixelafd                  │
        │ bundle/labelmap                  │
        │ bundle/recognize                 │
        │ bundle/stats                     │
        │ bundle/uniformize                │
        │ connectivity/afdfixel            │
        │ connectivity/decompose           │
        │ connectivity/visualize           │
        │ denoising/mppca                  │
        │ denoising/nlmeans                │
        │ image/applymask                  │
        │ image/burnvoxels                 │
        │ image/convert                    │
        │ image/cropvolume                 │
        │ image/powderaverage              │
        │ image/resample                   │
        │ io/nii2dcm                       │
        │ io/readbids                      │
        │ preproc/eddy                     │
        │ preproc/gibbs                    │
        │ preproc/n4                       │
        │ preproc/normalize                │
        │ preproc/topup                    │
        │ reconst/diffusivitypriors        │
        │ reconst/dtimetrics               │
        │ reconst/fodf                     │
        │ reconst/freewater                │
        │ reconst/frf                      │
        │ reconst/ihmt                     │
        │ reconst/meanfrf                  │
        │ reconst/noddi                    │
        │ reconst/shmetrics                │
        │ reconst/shsignal                 │
        │ registration/anattodwi           │
        │ registration/ants                │
        │ registration/antsapplytransforms │
        │ registration/convert             │
        │ registration/easyreg             │
        │ registration/synthregistration   │
        │ registration/tractogram          │
        │ segmentation/fastseg             │
        │ segmentation/fastsurfer          │
        │ segmentation/freesurferseg       │
        │ segmentation/fsreconall          │
        │ segmentation/synthseg            │
        │ stats/metricsinroi               │
        │ tracking/localtracking           │
        │ tracking/pfttracking             │
        │ tractogram/densitymap            │
        │ tractogram/removeinvalid         │
        │ tractogram/resample              │
        │ utils/extractb0                  │
        └──────────────────────────────────┘
        ```
   </span>
   </CommandOutputs>


:::note
On a first run of the commands, you may get prompted to configure some aspects of `nf-core`. You can accept every
prompt you see.
:::

:::caution
If you get an error saying `nf-core` command doesn't exists, then `poetry` has failed to load in the terminal
correctly. First, close your terminal, open a new one and try again. If the tool still cannot be found, try the
command `poetry shell`, then running `nf-core modules install` again. If this does not solve the problem, [open an
issue](https://github.com/scilus/nf-neuro/issues/new?template=bug_report.md) on the `nf-neuro` repository.
:::

### Install a new module

Now, you can install the modules you want to include in your pipeline. 
Let's install the `denoising/nlmeans` module for DWI denoising. 
You can install modules using `nf-core modules install` command.
The new module will be installed to the `./modules/nf-neuro/modules/` directory.


   <CommandOutputs>
   <span slot="command">
    ```bash
        nf-core modules install denoising/nlmeans
    ```
   </span>
   <span slot="output">
   You should see this output:
    ```
                                          ,--./,-.
          ___     __   __   __   ___     /,-._.--~\
    |\ | |__  __ /  ` /  \ |__) |__         }  {
    | \| |       \__, \__/ |  \ |___     \`-._,-`-,
                                          `._,._,'

    nf-core/tools version 2.14.1 - https://nf-co.re
    There is a new version of nf-core/tools available! (3.2.0)


    INFO     Installing 'denoising/nlmeans'                                                                                                                                        
    INFO     Use the following statement to include this module:                                                                                                                   
                                                                                                                                                                                
    include { DENOISING_NLMEANS } from '../modules/nf-neuro/denoising/nlmeans/main'  
    ```

    :::note
    By default nf-core prints the include command with a `../modules/[...]`.
    In this tutorial, you need to delete a directory, like this `./modules/[...]`.
    :::
   </span>
   </CommandOutputs>

### Configure and Use the Module

The purpose of adding this module is to denoise the DWI image before computing the DTI metrics.
To do this, simply repeat the sequence of sub-steps seen in 
**Step 3: How to use and configure an nf-neuro module in the workflow**.

<Steps>

1. Include the module in `main.nf`.

2. Bind the module in your `workflow`.

3. Prepare the input data structure for denoising module.

    Unlike the DTI module, where input data can be provided directly, 
    the MPPCA denoising module requires only the DWI image and an optional mask.

    The challenge is to leverage NextFlow tools to restructure the input data, 
    making it easier to handle. The goal is to efficiently retrieve specific files, 
    such as the DWI image or the BVEC and BVAL files. 
    To achieve this, we'll use NextFlow's [multiMap](https://www.nextflow.io/docs/latest/reference/operator.html#multimap)
    operator to generate multiple output channels from a single input channel, as shown below.

    <Tabs>
    <TabItem label="Command to add">
    ```nextflow
    ch_dwi_bvalbvec = inputs.dwi
        .multiMap { meta, dwi, bval, bvec ->
            dwi:            [ meta, dwi ]
            bvs_files:      [ meta, bval, bvec ]
            dwi_bval_bvec:  [ meta, dwi, bval, bvec ]
        }
    ```
    </TabItem>
    <TabItem label="Let's break it down">
    <Steps>

    1. `inputs.dwi` is the input channel from `get_data` containing : meta, dwi, bval, and bvec.

    2. The [multiMap](https://www.nextflow.io/docs/latest/reference/operator.html#multimap) : creates three new entries in different output channels:

            a. dwi: This output contains the meta information and the dwi file. 
            
            b. bvs_files: This output contains the meta information, bval file, and bvec file. 
            
            c. dwi_bval_bvec: This output contains all four elements from the input.

    3. ch_dwi_bvalbvec : Allows easy access to different file groups
    
        The result of this operation is a multi-channel object, and you can access these channels as follows:

            ch_dwi_bvalbvec.dwi : [meta, dwi]

            ch_dwi_bvalbvec.bvs_files : [meta, bval, bvec]

            ch_dwi_bvalbvec.dwi_bval_bvec : [meta, dwi, bval, bvec]

    </Steps>

    </TabItem>
    </Tabs>

    :::note
    Why Use `multiMap`?

    This approach is useful in Nextflow workflows when different processes require distinct subsets or 
    different combinations of your input data.
    With `multiMap`, you can also efficiently provide the right data to each process without duplicating it in your workflow.

    As in this tutorial, you might have one process that only needs the dwi file, another that needs the bval 
    and bvec files, and a third that needs all of them. 

4. Configure the denosing module in the `nextflow.config` using API Documentation [here](https://scilus.github.io/nf-neuro/api/modules/denoising/mppca/)

5. Adapt the input for `RECONST_DTIMETRICS` module to integrate denoised DWI.

    <Tabs>
    <TabItem label="Command to add in workflow">
    ```nextflow
    // Add this command just after the DENOISING_MPPCA module
    ch_dwi_denoised = DENOISING_MPPCA.out.image

    // You can now reuse the outputs and supply them to another module!
    // Update the input for RECONST_DTIMETRIC with DWI denoised output
    input_dti_denoised = ch_dwi_denoised
            .join(ch_dwi_bvalbvec.bvs_files)
            .map{ it + [[]] }

    // Update input name
    RECONST_DTIMETRICS( input_dti_denoised )
    ```
    </TabItem>
    <TabItem label="Let's break it down">
    <Steps>

    1. `DENOISING_MPPCA.out.image` : stores the denoised output.
      
        Assign the output from DENOISING_MPPCA to a new channel named `ch_dwi_denoised`. 
        Specifically, it's taking the `image` output.

        The **name** of a module's **output(s)** can be determined via the API Documentation in the `Outputs` section.

    2. `.join(ch_dwi_bvalbvec.bvs_files)`: merges it with BVAL/BVEC data
    
        The [join](https://www.nextflow.io/docs/latest/reference/operator.html#join)
        operator is used here to combine the items from `ch_dwi_denoised` with items from another channel `ch_dwi_bvalbvec.bvs_files`.
        The join operation matches items from both channels based on a common key (by default, the first element of each item).

    3. `.map{ it + [[]] }`:  Adds an empty list ([]) to each input tuple.
    
        After joining, we use map to transforms each item in the channel, and adding an empty list [[]], 
        for the optional mask input. The map operation is similar to the one we did for the DTI module in **Step 2**.

    </Steps>

    </TabItem>
    </Tabs>



6. Run and Verify the Pipeline : 

    <Tabs>
    <TabItem label="Check if it works">

    ```bash
    nextflow run main.nf --input data -profile docker
    ```
    </TabItem>
    <TabItem label="Expected output">

    ```bash
    N E X T F L O W   ~  version 24.10.4

    Launching `main.nf` [astonishing_borg] DSL2 - revision: d69b63f305

    executor >  local (2)
    [ec/62dd72] process > DENOISING_MPPCA (sub-003_ses-01)    [100%] 1 of 1 ✔
    [6e/837a31] process > RECONST_DTIMETRICS (sub-003_ses-01) [100%] 1 of 1 ✔
    Completed at: Date Hour
    Duration    : 1m 19s
    CPU hours   : (a few seconds)
    Succeeded   : 2
    ```

    Check your resulting images in the results folder!

    </TabItem>
    <TabItem label="Expected main.nf">
    ```nextflow
    #!/usr/bin/env nextflow

    include { RECONST_DTIMETRICS } from './modules/nf-neuro/reconst/dtimetrics/main'
    include { DENOISING_MPPCA } from './modules/nf-neuro/denoising/mppca/main'

    workflow get_data {
        main:
            if ( !params.input ) {
                log.info "You must provide an input directory containing all images using:"
                log.info ""
                log.info "    --input=/path/to/[input]   Input directory containing your subjects"
                log.info "                        |"
                log.info "                        ├-- S1"
                log.info "                        |    └-- ses-01"
                log.info "                        |    |    ├-- anat"
                log.info "                        |    |    |   |--*t1.nii.gz"
                log.info "                        |    |    |--dwi"
                log.info "                        |    |    |   |--*dwi.nii.gz"
                log.info "                        |    |    |   ├-- *dwi.bval"
                log.info "                        |    |    |   └-- *dwi.bvec"
                log.info "                        |    └-- ses-02"            
                log.info "                        └-- S2"
                log.info "                             └-- ses-01"
                log.info "                             |     ├-- anat"
                log.info "                             |    |   |--*t1.nii.gz"
                log.info "                             |    |--dwi"
                log.info "                             |    |   |--*dwi.nii.gz"
                log.info "                             |    |   ├-- *dwi.bval"
                log.info "                             |    |   └-- *dwi.bvec"
                log.info "                             └-- ses-02" 
                log.info ""
                error "Please resubmit your command with the previous file structure."
            }

            input = file(params.input)
            // ** Loading all files. ** //
            dwi_channel = Channel.fromFilePairs("$input/**/**/dwi/*dwi.{nii.gz,bval,bvec}", size: 3, flat: true)
                { it.parent.parent.parent.name + "_" + it.parent.parent.name}
                .map{ sid, bvals, bvecs, dwi -> [ [id: sid], dwi, bvals, bvecs ] }
        emit:
            dwi = dwi_channel
    }

    workflow {
        inputs = get_data()

        // Use Multimap to split the tuple into multi inputs structure
        ch_dwi_bvalbvec = inputs.dwi
            .multiMap { meta, dwi, bval, bvec ->
                dwi:            [ meta, dwi ]
                bvs_files:      [ meta, bval, bvec ]
                dwi_bval_bvec:  [ meta, dwi, bval, bvec ]
            }

        // Denoising DWI
        input_dwi_denoise = ch_dwi_bvalbvec.dwi
                        .map{ it + [[]] }

        DENOISING_MPPCA( input_dwi_denoise )

        // Fetch specific output
        ch_dwi_denoised = DENOISING_MPPCA.out.image

        // Input DTI update with DWI denoised output
        input_dti_denoised = ch_dwi_denoised
                .join(ch_dwi_bvalbvec.bvs_files)
                .map{ it + [[]] }

        RECONST_DTIMETRICS( input_dti_denoised )

    }
    ```

    </TabItem>
    <TabItem label="Expected nextflow.config">
    ```nextflow
    profiles {
        docker {
            docker.enabled          = true
            conda.enabled           = false
            singularity.enabled     = false
            podman.enabled          = false
            shifter.enabled         = false
            charliecloud.enabled    = false
            apptainer.enabled       = false
            docker.runOptions       = '-u $(id -u):$(id -g)'
        }
    }

    manifest {
        name            = 'scilus/nf-neuro-tutorial'
        description     = """nf-neuro-tutorial is a Nextflow pipeline for processing neuroimaging data."""
        version         = '0.1dev'
    }

    params.input      = false
    params.output     = 'result'

    process {

        publishDir = { "${params.output}/$meta.id/${task.process.replaceAll(':', '-')}" }

        withName: "DENOISING_MPPCA" {
            ext.extent = 3
        }

        withName: "RECONST_DTIMETRICS" {
            ext.ad = false
            ext.evecs = false
            ext.evals = false
            ext.fa = true
            ext.ga = false
            ext.rgb = false
            ext.md = true
            ext.mode = false
            ext.norm = false
            ext.rd = false
            ext.tensor = false
            ext.nonphysical = false
            ext.pulsation = false
            ext.residual = false
            ext.b0_thr_extract_b0 = 10
            ext.dwi_shell_tolerance = 50
            ext.max_dti_shell_value = 1200
            ext.run_qc = false
        }
    }
    ```
    </TabItem>
    </Tabs>


</Steps>



## Step 5 :  Install and Use an nf-neuro Subworkflow

### Listing and Installing an nf-neuro Subworkflow

Similar to modules, you can list available `subworkflows` in a remote repository or those 
installed locally in your pipeline using the `nf-core subworkflows list` command. 
To view all the available subworkflows, use the `nf-core subworkflows list remote` command, 
which will display all subworkflows in the terminal.

   <CommandOutputs>
   <span slot="command">
    ```bash
       nf-core subworkflows list remote
    ```
   </span>
   <span slot="output">
   You should see this output:
    ```bash

                                            ,--./,-.
              ___     __   __   __   ___   /,-._.--~\
        |\ | |__  __ /  ` /  \ |__) |__       }  {
        | \| |       \__, \__/ |  \ |___   \`-._,-`-,
                                            `._,._,'

        nf-core/tools version 2.14.1 - https://nf-co.re
        There is a new version of nf-core/tools available! (3.2.0)


    INFO     Subworkflows available from https://github.com/scilus/nf-neuro.git (main):                                                                                                          
                                                                                                                                                                                                
    ┏━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃ Subworkflow Name        ┃
    ┡━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │ anatomical_segmentation │
    │ bundle_seg              │
    │ io_bids                 │
    │ load_test_data          │
    │ preproc_dwi             │
    │ preproc_t1              │
    │ registration            │
    │ topup_eddy              │
    │ tractoflow              │
    └─────────────────────────┘
    ```

   </span>
   </CommandOutputs>


Now, let's install the `PREPROC_T1` subworkflow, designed to preprocess T1-weighted MRI data.  
You can install the subworkflow using the `nf-core subworkflows install` command. 
The subworkflow will be installed in the `./subworkflows/nf-neuro/` directory.

   <CommandOutputs>
   <span slot="command">
    ```bash
       nf-core subworkflows install preproc_T1
    ```
   </span>
   <span slot="output">
   You should see this output:
    ```bash

                                            ,--./,-.
            ___     __   __   __   ___     /,-._.--~\
        |\ | |__  __ /  ` /  \ |__) |__         }  {
        | \| |       \__, \__/ |  \ |___     \`-._,-`-,
                                            `._,._,'

        nf-core/tools version 2.14.1 - https://nf-co.re
        There is a new version of nf-core/tools available! (3.2.0)


    INFO     Installing 'preproc_t1'                                                                                                                                                             
    INFO     Use the following statement to include this subworkflow:                                                                                                                            
                                                                                                                                                                                                
    include { PREPROC_T1 } from '../subworkflows/nf-neuro/preproc_t1/main' 
    ```

   </span>
   </CommandOutputs>


### Add New Data in the Input Pipeline Structure

To include a T1w image in the pipeline, follow the approach from **Step 2** for adding DWI images.
The necessary steps are: 

    <Tabs>
    <TabItem label="Tasks">
    <Steps>

    1. Add T1w image path to `get_data` input structure.

    2. `emit` a new output channel called `anat`.

    3. Include the T1 channel data in the worflow and visualize it.

    4. Run the pipeline using `nextflow run main.nf --input data -profile docker`.

    </Steps>

    </TabItem>
    <TabItem label="Expected main.nf">
    ```nextflow
        #!/usr/bin/env nextflow

        include { RECONST_DTIMETRICS } from './modules/nf-neuro/reconst/dtimetrics/main'
        include { DENOISING_MPPCA } from './modules/nf-neuro/denoising/mppca/main'
        include { PREPROC_T1 } from './subworkflows/nf-neuro/preproc_t1/main'

        workflow get_data {
            main:
                if ( !params.input ) {
                    log.info "You must provide an input directory containing all images using:"
                    log.info ""
                    log.info "    --input=/path/to/[input]   Input directory containing your subjects"
                    log.info "                        |"
                    log.info "                        ├-- S1"
                    log.info "                        |    ├-- *dwi.nii.gz"
                    log.info "                        |    ├-- *dwi.bval"
                    log.info "                        |    ├-- *dwi.bvec"
                    log.info "                        |    └-- *t1.nii.gz"
                    log.info "                        └-- S2"
                    log.info "                             ├-- *dwi.nii.gz"
                    log.info "                             ├-- *bval"
                    log.info "                             ├-- *bvec"
                    log.info "                             └-- *t1.nii.gz"
                    log.info ""
                    error "Please resubmit your command with the previous file structure."
                }

                input = file(params.input)
                // ** Loading DWI files. ** //
                dwi_channel = Channel.fromFilePairs("$input/**/**/dwi/*dwi.{nii.gz,bval,bvec}", size: 3, flat: true)
                    { it.parent.parent.parent.name + "_" + it.parent.parent.name} // Set the subject filename as subjectID + '_' + session.
                    .map{ sid, bvals, bvecs, dwi -> [ [id: sid], dwi, bvals, bvecs ] } // Reordering the inputs.
                // ** Loading T1 file. ** //
                t1_channel = Channel.fromFilePairs("$input/**/**/anat/*T1w.nii.gz", size: 1, flat: true)
                    { it.parent.parent.parent.name + "_" + it.parent.parent.name } // Set the subject filename as subjectID + '_' + session.
                    .map{ sid, t1 -> [ [id: sid], t1 ] }
            emit:
                dwi = dwi_channel 
                anat = t1_channel
        }

        workflow {
            inputs = get_data()

            // Use Multimap to split the tuple into multi inputs structure
            ch_dwi_bvalbvec = inputs.dwi
                .multiMap { meta, dwi, bval, bvec ->
                    dwi:            [ meta, dwi ]
                    bvs_files:      [ meta, bval, bvec ]
                    dwi_bval_bvec:  [ meta, dwi, bval, bvec ]
                }

            // Denoising DWI
            input_dwi_denoise = ch_dwi_bvalbvec.dwi
                            .map{ it + [[]] }
            DENOISING_MPPCA( input_dwi_denoise )

            // Fetch specific output
            ch_dwi_denoised = DENOISING_MPPCA.out.image

            // Input DTI update with DWI denoised output
            input_dti_denoised = ch_dwi_denoised
                    .join(ch_dwi_bvalbvec.bvs_files)
                    .map{ it + [[]] }

            // DTI-derived metrics
            RECONST_DTIMETRICS( input_dti_denoised )

            // Preprocessing T1 images
            inputs.anat.view()

        }
    ```
    </TabItem>
    <TabItem label="Expected output">
    ```bash
    Launching `main.nf` [evil_noether] DSL2 - revision: f131ccc34c

    executor >  local (2)
    [c8/fa8ee7] process > DENOISING_MPPCA (sub-003_ses-01)    [100%] 1 of 1 ✔
    [e9/6b32bf] process > RECONST_DTIMETRICS (sub-003_ses-01) [100%] 1 of 1 ✔

    [[id:sub-003_ses-01], /workspaces/nf-neuro-tutorial_test/data/sub-003/ses-01/anat/sub-003_ses-01_T1w.nii.gz]
    ```
    </TabItem>
    </Tabs>


### Bind the Subworkflow and Prepare the Input subworflow Structure

 <Steps>

 1. Bind the subworkflow as follows:

    ```nextflow
    PREPROC_T1( input_channel(s) )
    ```

 2. Prepare structure input for subworkflow. 

    As with modules, the API documentation also lists **subworkflows**, 
    providing information on **Inputs**, **Outputs**, and the module list used in the 
    **Components** section:  [PREPROC_T1](https://scilus.github.io/nf-neuro/api/subworkflows/preproc_t1/).

    The PREPROC_T1 process has 7 input channels defined, with only ch_image being mandatory.
    Just like using an empty list for modules, using an **empty channel** allows the 
    process to run without optional inputs.

        - ch_image (Mandatory)
        - ch_template (Optional)
        - ch_probability_map (Optional)
        - ch_mask_nlmeans (Optional)
        - ch_ref_n4 (Optional)
        - ch_ref_resample (Optional)
        - ch_weights (Optional)

    <Tabs>
    <TabItem label="Tasks">

    Use the `Channel.empty()` function for optional inputs, try to define the input structure for PREPROC_T1.

    </TabItem>
    <TabItem label="Expected command">
    ```nextflow

        PREPROC_T1(
            inputs.anat,
            Channel.empty(),
            Channel.empty(),
            Channel.empty(),
            Channel.empty(),
            Channel.empty(),
            Channel.empty()
        )
    ```
    </TabItem>
    </Tabs>

 </Steps>


### Configure your subworkflow

Configuring a subworkflow requires understanding the modules used and the associated parameters.

The [PREPROC_T1](https://scilus.github.io/nf-neuro/api/subworkflows/preproc_t1/) API documentation 
lists the modules included in the subworkflow in the **Components** section : 

        - denoising/nlmeans
        - preproc/n4
        - image/resample
        - betcrop/antsbet
        - betcrop/synthbet
        - image/cropvolume

However, it does not yet provide a list of the parameters associated with the subworkflows. 
You can find the parameters for the subworflow in the `./subworkflow/nf-neuro/preproc_t1/main.nf` 
file or the `nextflow.config` file within the **tests** folder (`./subworkflow/nf-neuro/preproc_t1/tests/nextflow.config`).

For simplicity's sake, we will enable the `denoising` and `synthbet` options (set to `true`) and 
disable all other options (set to `false`). 

Add the following to your `nextflow.config` file:

```nextflow
    // Add those line after params.output = 'result'

    // ** Subworkflow PREPROC T1 **
    params.preproc_t1_run_denoising = true
    params.preproc_t1_run_N4 = true
    params.preproc_t1_run_resampling = false
    params.preproc_t1_run_ants_bet = false
    params.preproc_t1_run_synthbet = true
    params.preproc_t1_run_crop = false

```

Since we are disabling all options except for `denoising` and `synthbet`, we only need to 
include the parameters for the modules corresponding to those options. 
Note that the `denoising` module does not require any specific parameters, so it can be ignored in the configuration.

Now, update your `nextflow.config` file by adding the specific options for the subworkflow in the process section as follows:

```nextflow
    // Add those line in the process {} after DENOISING_MPPCA :

    withName: "BETCROP_SYNTHBET" {
        memory = "4G"
        ext.nocsf = false
    }
```

Now you can run and validate your pipeline:

<Tabs>
<TabItem label="Check if it works">
If you don't want to recompute each image, you can add the `-resume` option to your command line.
```bash
nextflow run main.nf --input data -profile docker 
```
</TabItem>
<TabItem label="Expected output">
```bash
    N E X T F L O W   ~  version 24.10.4

    Launching `main.nf` [dreamy_lichterman] DSL2 - revision: 1af7463284

    executor >  local (4)
    [4a/908262] DENOISING_MPPCA (sub-003_ses-01)              [100%] 1 of 1 ✔
    [29/a93bfe] RECONST_DTIMETRICS (sub-003_ses-01)           [100%] 1 of 1 ✔
    [f5/79c402] PREPROC_T1:DENOISING_NLMEANS (sub-003_ses-01) [100%] 1 of 1 ✔
    [ef/10c1d5] PREPROC_T1:BETCROP_SYNTHBET (sub-003_ses-01)  [100%] 1 of 1 ✔
    Completed at: Date Hour
    Duration    : 6m 14s
    CPU hours   : 0.1
    Succeeded   : 4
```

</TabItem>
<TabItem label="Expected main.nf">
```nextflow
    #!/usr/bin/env nextflow

    include { RECONST_DTIMETRICS } from './modules/nf-neuro/reconst/dtimetrics/main'
    include { DENOISING_MPPCA } from './modules/nf-neuro/denoising/mppca/main'
    include { PREPROC_T1 } from './subworkflows/nf-neuro/preproc_t1/main'

    workflow get_data {
        main:
            if ( !params.input ) {
                log.info "You must provide an input directory containing all images using:"
                log.info ""
                log.info "    --input=/path/to/[input]   Input directory containing your subjects"
                log.info "                        |"
                log.info "                        ├-- S1"
                log.info "                        |    ├-- *dwi.nii.gz"
                log.info "                        |    ├-- *dwi.bval"
                log.info "                        |    ├-- *dwi.bvec"
                log.info "                        |    └-- *t1.nii.gz"
                log.info "                        └-- S2"
                log.info "                             ├-- *dwi.nii.gz"
                log.info "                             ├-- *bval"
                log.info "                             ├-- *bvec"
                log.info "                             └-- *t1.nii.gz"
                log.info ""
                error "Please resubmit your command with the previous file structure."
            }

            input = file(params.input)
            // ** Loading DWI files. ** //
            dwi_channel = Channel.fromFilePairs("$input/**/**/dwi/*dwi.{nii.gz,bval,bvec}", size: 3, flat: true)
                { it.parent.parent.parent.name + "_" + it.parent.parent.name} // Set the subject filename as subjectID + '_' + session.
                .map{ sid, bvals, bvecs, dwi -> [ [id: sid], dwi, bvals, bvecs ] } // Reordering the inputs.
            // ** Loading T1 file. ** //
            t1_channel = Channel.fromFilePairs("$input/**/**/anat/*T1w.nii.gz", size: 1, flat: true)
                { it.parent.parent.parent.name + "_" + it.parent.parent.name } // Set the subject filename as subjectID + '_' + session.
                .map{ sid, t1 -> [ [id: sid], t1 ] }
        emit:
            dwi = dwi_channel 
            anat = t1_channel
    }

    workflow {
        inputs = get_data()

        // Use Multimap to split the tuple into multi inputs structure
        ch_dwi_bvalbvec = inputs.dwi
            .multiMap { meta, dwi, bval, bvec ->
                dwi:            [ meta, dwi ]
                bvs_files:      [ meta, bval, bvec ]
                dwi_bval_bvec:  [ meta, dwi, bval, bvec ]
            }

        // Denoising DWI
        input_dwi_denoise = ch_dwi_bvalbvec.dwi
                        .map{ it + [[]] }
        DENOISING_MPPCA( input_dwi_denoise )

        // Fetch specific output
        ch_dwi_denoised = DENOISING_MPPCA.out.image

        // Input DTI update with DWI denoised output
        input_dti_denoised = ch_dwi_denoised
                .join(ch_dwi_bvalbvec.bvs_files)
                .map{ it + [[]] }

        // DTI-derived metrics
        RECONST_DTIMETRICS( input_dti_denoised )

        // Preprocessing T1 images
        //inputs.anat.view()
        
        PREPROC_T1(
            input_t1,
            Channel.empty(),
            Channel.empty(),
            Channel.empty(),
            Channel.empty(),
            Channel.empty(),
            Channel.empty()
        )

    }
```
</TabItem>
<TabItem label="Expected nextflow.config">
```nextflow
    profiles {
        docker {
            docker.enabled          = true
            conda.enabled           = false
            singularity.enabled     = false
            podman.enabled          = false
            shifter.enabled         = false
            charliecloud.enabled    = false
            apptainer.enabled       = false
            docker.runOptions       = '-u $(id -u):$(id -g)'
        }
    }

    manifest {
        name            = 'scilus/nf-neuro-tutorial'
        description     = """nf-neuro-tutorial is a Nextflow pipeline for processing neuroimaging data."""
        version         = '0.1dev'
    }

    params.input      = false
    params.output     = 'result'

    // ** Subworkflow PREPROC T1 **
    params.preproc_t1_run_denoising = true
    params.preproc_t1_run_N4 = false
    params.preproc_t1_run_resampling = false
    params.preproc_t1_run_ants_bet = false
    params.preproc_t1_run_synthbet = true
    params.preproc_t1_run_crop = false


    process {

        publishDir = { "${params.output}/$meta.id/${task.process.replaceAll(':', '-')}" }

        withName: "DENOISING_MPPCA" {
            ext.extent = 3
        }

        withName: "BETCROP_SYNTHBET" {
            memory = "4G"
            ext.nocsf = false
        }

        withName: "RECONST_DTIMETRICS" {
            ext.ad = false
            ext.evecs = false
            ext.evals = false
            ext.fa = true
            ext.ga = false
            ext.rgb = false
            ext.md = true
            ext.mode = false
            ext.norm = false
            ext.rd = false
            ext.tensor = false
            ext.nonphysical = false
            ext.pulsation = false
            ext.residual = false
            ext.b0_thr_extract_b0 = 10
            ext.dwi_shell_tolerance = 50
            ext.max_dti_shell_value = 1200
            ext.run_qc = false
        }
    }
    ```
</TabItem>
</Tabs>



## Step 6 : Create your own local module 

In this step, we will create a local module called `METRICSINROI` under the `STATS` category, 
designed for segmenting a T1-weighted (T1w) image and extracting metrics from white matter (WM), 
gray matter (GM), and cerebrospinal fluid (CSF) masks.

### Creating a Local Module structure

    Create the following directory structure, including a main.nf file inside the module folder:

    `stats` = category and `metricsinrois` = module name
    ```
    nf-neuro-tutorial/
    ├── ...
    ├── modules/
    │   ├── local/
    │   │   ├── stats/metricsinrois/main.nf
    │   ├── nf-neuro/
    |   |   |--categories/modules
    └── ...
    ```

### Write the local module

(faire le lien avec contribute ?, je dirais non, a voir)


A Nextflow module is a file containing one process that execute one or more command. 
The structure of a module should look like this:

    <Tabs>
    <TabItem label="Example of module">

    ```
    process CATEGORY_MODULE {
        tag "$meta.id"
        label 'process_single'

        container "${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?
            'https://scil.usherbrooke.ca/containers/scilus_latest.sif':
            'scilus/scilus:latest' }"

        input:
        tuple val(meta), path(input_file)
        
        output:
        tuple val(meta), path("output.txt") , emit: outputname
        
        script:
        def prefix = task.ext.prefix ?: "${meta.id}"
        def optionName = task.ext.option ? "${task.ext.option}" : "default_value"
        """
        cat ${input_file} > output.txt
        """
    }
    ```

    </TabItem>
    <TabItem label="Let's break it down">
    <Steps>
    1. `tag "$meta.id"`
        This assigns a tag to the process using the 'id' field from the 'meta' map. 
        Tags are useful for logging and tracking purposes.

    2. `label 'process_single'`
        This assigns a label to the process, which can be used for 
        resource allocation or other configuration purposes.

    3. `container`
        Specifies the container to use for the process. 
        It conditionally chooses between a Singularity or Docker container based on the workflow configuration.

    4. `Input`
        Defines the input for the process as a tuple containing 
        metadata (meta) and an input file path.

    5. `Output`
        Defines the output of the process as a tuple containing 
        the input metadata and a file named "output.txt". 
        The output is emitted to a channel named "outputname".

    6. `script`
        This is the script that will be executed by the process. 
        It defines some option a `prefix` variable using a `task` extension or the meta id.
        Defines an 'optionName' variable using a task extension or a default value.

        Here it, execute a simple command to copy the contents of the input file to output.txt.
    </Steps>

    In summary, this process takes an input file, copies its contents to an output file,
     and provides some flexibility in naming and options through the use of metadata and task extensions. 
     The process can run in either a Singularity or Docker container, depending on the workflow configuration.

    </TabItem>
    <TabItem label="Tasks">

    The goal of this local module is to segment a T1-weighted (T1w) image using `fast` and 
    extract metrics from the white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF) 
    masks using the `scil_volume_stats_in_ROI.py` script.

    You can copy and paste the example module into your `main.nf` file. First, rename the process 
    `STATS_METRICSINROI` and then modify it using the steps below:

    <Steps>
    
    1. Modify `input` to include T1 and metrics
        ```nextflow
        tuple val(meta), path(t1), path(metrics)
        ```

    2. Update `output` to include segmentation maps and masks, as well as the JSON output from silpy script. 
        Example for WM data :

        ```nextflow
            output:
            tuple val(meta), path("*.json")                         , emit: stats
            tuple val(meta), path("*mask_wm.nii.gz")                , emit: wm_mask
            tuple val(meta), path("*map_wm.nii.gz")                 , emit: wm_map

        ```

    3. Include `task` extensions for additional options (those from scilpy script):

        ```nextflow
            script:
            def prefix = task.ext.prefix ?: "${meta.id}"
            def bin = task.ext.bin ? "--bin " : ""
            def normalize_weights = task.ext.normalize_weights ? "--normalize_weights " : ""
        ```

    4. Modify the `script`
        <Steps>
            1. Update the script to perform segmentation using `fast` on the T1w image.

            2. Generate binary masks for each PVE tissue segmentation using `scil_volume_math.py` or another tool.
            
            3. Rename PVE outputs from `fast` to map_*.nii.gz and mask_*.nii.gz

            4. Extract metrics from the WM, GM and CSF binary masks using `scil_volume_stats_in_ROI.py` or other.
        </Steps>

        :::note
            ### **Add a `meta.yml` File for Local Modules and Subworkflows**  

            When working with local modules in Nextflow, you can add a `meta.yml` file to store metadata. 
            This file provides useful details about the module or subworkflow, making it easier to understand and use.  

            #### **Why Use `meta.yml`?**  

            - It serves as a metadata file that contains essential information about a module or subworkflow, 
            and helps document the component, making it more accessible to other users and developers.  

            #### **Where to Place the `meta.yml` File?** 

            - **For Modules:** `./modules/nf-core/<module_name>/meta.yml`  
            - **For Subworkflows:** `./subworkflows/nf-core/<subworkflow_name>/meta.yml`  

            #### **What Does `meta.yml` Contain?**  

            - General information about the module or subworkflow  
            - Author details  
            - A brief description of input and output files used in the main script (specific to each module or subworkflow)  

            If you're looking for an **example**, you can find a `meta.yml` file in the nf-neuro repository, within its  
            modules/subworkflows directory. This example provides a structured reference for how to document your own modules/subworkflows.

            By including a `meta.yml` file, you ensure better documentation and maintainability of your Nextflow components.
        :::

    </Steps>

    </TabItem>
    <TabItem label="Expected module">
    ```nextflow
        process STATS_METRICSINROI {
            tag "$meta.id"
            label 'process_single'

            container "${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?
                'https://scil.usherbrooke.ca/containers/scilus_latest.sif':
                'scilus/scilus:latest' }"

            input:
            tuple val(meta), path(t1), path(metrics)

            output:
            tuple val(meta), path("*.json")                         , emit: stats
            tuple val(meta), path("*mask_wm.nii.gz")                , emit: wm_mask
            tuple val(meta), path("*mask_gm.nii.gz")                , emit: gm_mask
            tuple val(meta), path("*mask_csf.nii.gz")               , emit: csf_mask
            tuple val(meta), path("*map_wm.nii.gz")                 , emit: wm_map
            tuple val(meta), path("*map_gm.nii.gz")                 , emit: gm_map
            tuple val(meta), path("*map_csf.nii.gz")                , emit: csf_map

            script:
            def prefix = task.ext.prefix ?: "${meta.id}"
            def bin = task.ext.bin ? "--bin " : ""
            def normalize_weights = task.ext.normalize_weights ? "--normalize_weights " : ""
            """
            export ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS=1
            export OMP_NUM_THREADS=1
            export OPENBLAS_NUM_THREADS=1

            fast -t 1 -n 3\
                -H 0.1 -I 4 -l 20.0 -g -o t1.nii.gz $t1
            scil_volume_math.py convert t1_seg_2.nii.gz ${prefix}__mask_wm.nii.gz --data_type uint8
            scil_volume_math.py convert t1_seg_1.nii.gz ${prefix}__mask_gm.nii.gz --data_type uint8
            scil_volume_math.py convert t1_seg_0.nii.gz ${prefix}__mask_csf.nii.gz --data_type uint8
            mv t1_pve_2.nii.gz ${prefix}__map_wm.nii.gz
            mv t1_pve_1.nii.gz ${prefix}__map_gm.nii.gz
            mv t1_pve_0.nii.gz ${prefix}__map_csf.nii.gz

            scil_volume_stats_in_ROI.py ${prefix}__mask*.nii.gz  \
                --metrics $metrics \
                --sort_keys \
                $bin $normalize_weights > ${prefix}__stats.json

            """
        }
    ```
    </TabItem>
    </Tabs>


### Bind and Prepare the Input Structure of the Local Module in the Pipeline

#### Bind your local module

You can now include and bind your local module to the workflow, as shown in the previous steps::

```nextflow
// Add this line on the top of the main.nf
 include { STATS_METRICSINROI } from './modules/local/stats/metricsinrois/main'

 // Add the local module in the workflow
 STATS_METRICSINROI( input_channel )

 ```

### Prepare the input channel for your local module

The STATS_METRICSINROIS module requires two inputs: a T1 image and metrics. 

   <Tabs>
    <TabItem label="Task">

    You can use the `join()` and `map()` operators 
    to create an input channel that combines the T1 BET image output from the 
    `PREPROC_T1` subworkflow with the FA map from the DTI module.

    Add the input channel to the module.

    </TabItem>
    <TabItem label="Expected input channel">

        ```nextflow
        input_extract_metric = PREPROC_T1.out.image_bet
                    .join(RECONST_DTIMETRICS.out.fa)
                    .map{ it }

        STATS_METRICSINROI( input_extract_metric )
        ```
    </TabItem>
    </Tabs>


### Configure your local module

To configure your local module, you need to add each task.ext.* to the module. 

   <Tabs>
    <TabItem label="Task">

    As we’ve seen previously, use the `withName` process selector to link the `ext` 
    parameter defined in your local module to `nextflow.config` file.

    </TabItem>
    <TabItem label="Expected nextflow.config">

        ```nextflow
            withName: "STATS_METRICSINROI" {
                ext.bin = true
                ext.normalize_weights = false
            }
        ```
    </TabItem>
    </Tabs>

You now have a working local module in your Nextflow pipeline! 

    <Tabs>
    <TabItem label="Check if it works">

    ```bash
    nextflow run main.nf --input data -profile docker
    ```

    </TabItem>
    <TabItem label="Expected output">
    ```bash
    N E X T F L O W   ~  version 24.10.4

    Launching `main.nf` [dreamy_lichterman] DSL2 - revision: 1af7463284

    executor >  local (5)
    [4a/908262] DENOISING_MPPCA (sub-003_ses-01)              [100%] 1 of 1 ✔
    [29/a93bfe] RECONST_DTIMETRICS (sub-003_ses-01)           [100%] 1 of 1 ✔
    [f5/79c402] PREPROC_T1:DENOISING_NLMEANS (sub-003_ses-01) [100%] 1 of 1 ✔
    [ef/10c1d5] PREPROC_T1:BETCROP_SYNTHBET (sub-003_ses-01)  [100%] 1 of 1 ✔
    [3f/56e48b] STATS_METRICSINROI (sub-003_ses-01)           [100%] 1 of 1 ✔
    Completed at: Date Hour
    Duration    : 6m 14s
    CPU hours   : 0.1
    Succeeded   : 5
    ```

    </TabItem>
    <TabItem label="Expected main.nf">
    ```nextflow
        #!/usr/bin/env nextflow

        include { RECONST_DTIMETRICS } from './modules/nf-neuro/reconst/dtimetrics/main'
        include { DENOISING_MPPCA } from './modules/nf-neuro/denoising/mppca/main'
        include { PREPROC_T1 } from './subworkflows/nf-neuro/preproc_t1/main'
        include { STATS_METRICSINROI } from './modules/local/stats/metricsinrois/main'

        workflow get_data {
            main:
                if ( !params.input ) {
                    log.info "You must provide an input directory containing all images using:"
                    log.info ""
                    log.info "    --input=/path/to/[input]   Input directory containing your subjects"
                    log.info "                        |"
                    log.info "                        ├-- S1"
                    log.info "                        |    ├-- *dwi.nii.gz"
                    log.info "                        |    ├-- *dwi.bval"
                    log.info "                        |    ├-- *dwi.bvec"
                    log.info "                        |    └-- *t1.nii.gz"
                    log.info "                        └-- S2"
                    log.info "                             ├-- *dwi.nii.gz"
                    log.info "                             ├-- *bval"
                    log.info "                             ├-- *bvec"
                    log.info "                             └-- *t1.nii.gz"
                    log.info ""
                    error "Please resubmit your command with the previous file structure."
                }

                input = file(params.input)
                // ** Loading DWI files. ** //
                dwi_channel = Channel.fromFilePairs("$input/**/**/dwi/*dwi.{nii.gz,bval,bvec}", size: 3, flat: true)
                    { it.parent.parent.parent.name + "_" + it.parent.parent.name} // Set the subject filename as subjectID + '_' + session.
                    .map{ sid, bvals, bvecs, dwi -> [ [id: sid], dwi, bvals, bvecs ] } // Reordering the inputs.
                // ** Loading T1 file. ** //
                t1_channel = Channel.fromFilePairs("$input/**/**/anat/*T1w.nii.gz", size: 1, flat: true)
                    { it.parent.parent.parent.name + "_" + it.parent.parent.name } // Set the subject filename as subjectID + '_' + session.
                    .map{ sid, t1 -> [ [id: sid], t1 ] }
            emit:
                dwi = dwi_channel 
                anat = t1_channel
        }

        workflow {
            inputs = get_data()

            // Use Multimap to split the tuple into multi inputs structure
            ch_dwi_bvalbvec = inputs.dwi
                .multiMap { meta, dwi, bval, bvec ->
                    dwi:            [ meta, dwi ]
                    bvs_files:      [ meta, bval, bvec ]
                    dwi_bval_bvec:  [ meta, dwi, bval, bvec ]
                }

            // Denoising DWI
            input_dwi_denoise = ch_dwi_bvalbvec.dwi
                            .map{ it + [[]] }
            DENOISING_MPPCA( input_dwi_denoise )

            // Fetch specific output
            ch_dwi_denoised = DENOISING_MPPCA.out.image

            // Input DTI update with DWI denoised output
            input_dti_denoised = ch_dwi_denoised
                    .join(ch_dwi_bvalbvec.bvs_files)
                    .map{ it + [[]] }

            // DTI-derived metrics
            RECONST_DTIMETRICS( input_dti_denoised )

            // Preprocessing T1 images
            //inputs.anat.view()

            PREPROC_T1(
                inputs.anat,
                Channel.empty(),
                Channel.empty(),
                Channel.empty(),
                Channel.empty(),
                Channel.empty(),
                Channel.empty()
            )

            // Extract FA value 
            input_extract_metric = PREPROC_T1.out.image_bet
                    .join(RECONST_DTIMETRICS.out.fa)
                    .map{ it }
            //input_extract_metric.view()
            
            STATS_METRICSINROI( input_extract_metric )

        }
    ```

    </TabItem>
    <TabItem label="Expected nextflow.config">
    ```nextflow
        profiles {
            docker {
                docker.enabled          = true
                conda.enabled           = false
                singularity.enabled     = false
                podman.enabled          = false
                shifter.enabled         = false
                charliecloud.enabled    = false
                apptainer.enabled       = false
                docker.runOptions       = '-u $(id -u):$(id -g)'
            }
        }

        manifest {
            name            = 'scilus/nf-neuro-tutorial'
            description     = """nf-neuro-tutorial is a Nextflow pipeline for processing neuroimaging data."""
            version         = '0.1dev'
        }

        params.input      = false
        params.output     = 'result'

        // ** Subworkflow PREPROC T1 **
        params.preproc_t1_run_denoising = true
        params.preproc_t1_run_N4 = false
        params.preproc_t1_run_resampling = false
        params.preproc_t1_run_ants_bet = false
        params.preproc_t1_run_synthbet = true
        params.preproc_t1_run_crop = false


        process {

            publishDir = { "${params.output}/$meta.id/${task.process.replaceAll(':', '-')}" }

            withName: "DENOISING_MPPCA" {
                ext.extent = 3
            }

            withName: "BETCROP_SYNTHBET" {
                memory = "4G"
                ext.nocsf = false
            }

            withName: "RECONST_DTIMETRICS" {
                ext.ad = false
                ext.evecs = false
                ext.evals = false
                ext.fa = true
                ext.ga = false
                ext.rgb = false
                ext.md = true
                ext.mode = false
                ext.norm = false
                ext.rd = false
                ext.tensor = false
                ext.nonphysical = false
                ext.pulsation = false
                ext.residual = false
                ext.b0_thr_extract_b0 = 10
                ext.dwi_shell_tolerance = 50
                ext.max_dti_shell_value = 1200
                ext.run_qc = false
            }

            withName: "STATS_METRICSINROI" {
                ext.bin = true
                ext.normalize_weights = false
            }
        }
    ```
    </TabItem>
    </Tabs>


## Step 7 : Reorganize modules in subworkflow

In this step, we will create a local subworkflow called `PREPROC_DIFF` which include 
the two first modules used in your pipeline: DENOISING_MPPCA and RECONST_DTIMETRICS.

### Creating a Local subworflow structure

    Create the following local directory structure, including a main.nf file inside the subworflow folder:

    ```
    nf-neuro-tutorial/
    ├── ...
    ├── subworflows/
    │   ├── local/
    │   │   ├── preproc_diff/main.nf
    │   ├── nf-neuro/
    |   |   |--load_test_data
    |   |   └──preproc_t1
    └── ...
    ```

### Write the subworflow module

(faire le lien avec contribute ?, je dirais non, a voir)

A Nextflow subworflow is a file containing at least two modules. 
The structure of a subworflow should look like this:

    <Tabs>
    <TabItem label="Example of module">

    This workflow demonstrates the use of Nextflow DSL2 features such as module inclusion, 
    workflow definition with input and output channels, conditional process execution, 
    and channel manipulation.

    ```
    include { MODULE1 } from '../../../path/module1/main'
    include { MODULE2 } from '../../../path/module2/main'

    workflow SUBWORKFLOW_NAME {

        take:
            input_channel           // channel: [ val(meta), input1, input2, input3 ]

        main:

            reorganize_input_channel = ()

            // ** description MODULE 1 ** //
            if (params.run_mdoule1) {
                input_channel_module1 = ()

                MODULE1 ( input_channel_module1 )

                // Output channel
                output_option = MODULE1.out.output_name
                    .join(reorganize_input_channel.outname_2)
            }

            // ** description MODULE 2 ** //
            input_channel_module2 = ()
            MODULE2( input_channel_module2 )

        emit:
            output_module1_1     = MODULE1.out.output1     // channel: [ val(meta), file ]
            output_module1_2     = output_option           // channel: [ val(meta), file1, file2 ]
            output_module2_1     = MODULE2.out.output1     // channel: [ val(meta), file ]
            output_module2_2     = MODULE2.out.output2     // channel: [ val(meta), file ]
    }
    ```

    </TabItem>
    <TabItem label="Let's break it down">
    <Steps>
    1. `include {}`

        A subworkflow is a workflow, so it is necessary to import the modules that need to be used in the workflow.

    2. `take` : Input channels

        The workflow takes one or more input channels containing metadata and files.

    3. `main`

        This section contains the main logic of the workflow

    4. `if (params.condition*)` : conditionnal option

        Conditional option : If the condition* parameter is set, 
        the workflow performs the optionnal module. 
        This parameter must then be added to the `nextflow.config`.

    5. input channel/modules

        Next, you need to define the input channels necessary for the modules being used.

    6. `emit` : Output Channels

        The workflow emits one or more output channels.

    </Steps>

    </TabItem>
    <TabItem label="Tasks">

    The purpose of this local subworkflow is to preprocess DWI data, 
    optionally apply denoising, and compute DTI-derived metrics. 
    
    Based on the "Example of module", create a local subworkflow that integrates the following two modules:

    **DENOISING_MPPCA** – Performs MP-PCA denoising on the dMRI data (optional).

    **RECONST_DTIMETRICS** – Computes DTI metrics : FA and MD.

    
    <Steps>
    1. Import Required Modules

        Include denoising_mppca and reconst_dtimetrics in your subworkflow.

        ```nextflow
        include { RECONST_DTIMETRICS } from '../../../modules/nf-neuro/reconst/dtimetrics/main'
        include { DENOISING_MPPCA } from '../../../modules/nf-neuro/denoising/mppca/main'
        ```
    2. Rename your worflow : `PREPROC_DIFF`

    3. Define Input Channels
        
        Specify the necessary input channels for the subworkflow.
        In this case you require the files dwi, bval and bvec.

        ```nextflow
            take:
                ch_dwi           // channel: [ val(meta), dwi, bval, bvec ]

        ```

    4. Implement `main:`
    
        <Tabs>
        <TabItem label="Tasks">

        Copy and paste the relevant denoising and DTI metrics sections into the workflow. 
        Then, modify the workflow structure to include a condition that runs denoising only if the option is enabled.

        Use the parameter name : `preproc_dwi_run_denoising`.

        </TabItem>
        <TabItem label="Expected main">

        ```nextflow

        // ** Denoise DWI ** //
        if (params.preproc_dwi_run_denoising) {
            ch_dwi_bvalbvec = ch_dwi
                .multiMap { meta, dwi, bval, bvec ->
                    dwi:    [ meta, dwi ]
                    bvs_files: [ meta, bval, bvec ]
                }

            ch_denoise_dwi = ch_dwi_bvalbvec.dwi
                .map{ it + [[]] }

            DENOISING_MPPCA ( ch_denoise_dwi )

            // Fetch specific output
            ch_dwi = DENOISING_MPPCA.out.image
                .join(ch_dwi_bvalbvec.bvs_files)
        }

        // Input DTI update with DWI denoised output
        input_dti = ch_dwi.map{ it + [[]] }

        // DTI-derived metrics
        RECONST_DTIMETRICS( input_dti )
        ```
        </TabItem>
        </Tabs>

    5. Define Output Channels
    
        Emit relevant output files, including original and processed dMRI data and DTI metrics.

        ```nextflow
            emit:
                dwi                 = ch_dwi_bvalbvec.dwi           // channel: [ val(meta), dwi-raw ]
                dwi_denoised        = DENOISING_MPPCA.out.image     // channel: [ val(meta), dwi-after-mppca ]
                bvs_files           = ch_dwi_bvalbvec.bvs_files     // channel: [ val(meta), bval, bvec ]
                fa                  = RECONST_DTIMETRICS.out.fa     // channel: [ val(meta), fa ]
                md                  = RECONST_DTIMETRICS.out.md     // channel: [ val(meta), md ]
        ```

    </Steps>

    </TabItem>
    <TabItem label="Expected subworkflow">
    ```nextflow
        include { RECONST_DTIMETRICS } from '../../../modules/nf-neuro/reconst/dtimetrics/main'
        include { DENOISING_MPPCA } from '../../../modules/nf-neuro/denoising/mppca/main'

        workflow PREPROC_DIFF {

            take:
                ch_dwi           // channel: [ val(meta), dwi, bval, bvec ]

            main:

                // ** Denoise DWI ** //
                if (params.preproc_dwi_run_denoising) {
                    ch_dwi_bvalbvec = ch_dwi
                        .multiMap { meta, dwi, bval, bvec ->
                            dwi:    [ meta, dwi ]
                            bvs_files: [ meta, bval, bvec ]
                        }

                    ch_denoise_dwi = ch_dwi_bvalbvec.dwi
                        .map{ it + [[]] }

                    DENOISING_MPPCA ( ch_denoise_dwi )

                    // Fetch specific output
                    ch_dwi = DENOISING_MPPCA.out.image
                        .join(ch_dwi_bvalbvec.bvs_files)
                }

                // Input DTI update with DWI denoised output
                input_dti = ch_dwi.map{ it + [[]] }

                // DTI-derived metrics
                RECONST_DTIMETRICS( input_dti )

            emit:
                dwi                 = ch_dwi_bvalbvec.dwi           // channel: [ val(meta), dwi-raw ]
                dwi_denoised        = DENOISING_MPPCA.out.image     // channel: [ val(meta), dwi-after-mppca ]
                bvs_files           = ch_dwi_bvalbvec.bvs_files     // channel: [ val(meta), bval, bvec ]
                fa                  = RECONST_DTIMETRICS.out.fa     // channel: [ val(meta), fa ]
                md                  = RECONST_DTIMETRICS.out.md     // channel: [ val(meta), md ]

        }
    ```
    </TabItem>
    </Tabs>


### Bind and Prepare the Input Structure of the Local subworkflow in the Pipeline

You can now include and bind your local subworflow to the workflow, as shown in the previous steps::

```nextflow

// Add this line on the top of the main.nf
 include { PREPROC_DIFF } from './subworkflows/local/preproc_diff/main'

 // Replace the section corresponding to the sub-worflow by calling 
 // PREPROC_DIFF() in the main.nf

 PREPROC_DIFF()

 ```

As we have defined the input of the subworkflow to take the DWI image and 
the bval and bvec files, you can directly provide the input data to the workflow.

```nextflow
 PREPROC_DIFF( inputs.dwi )
 ```

Last but not least, don't forget to adapt the input channels for the DTI metrics extraction module!

```nextflow
    input_extract_metric = PREPROC_T1.out.image_bet
            .join(PREPROC_DIFF.out.fa)
            .map{ it }
```

### Configure your Local Subworkflow

Finally, all that's left is to add the parameters defined in the subworkflow to the `nextflow.config` file.

```nextflow

    // ** Subworflow PREPROC_DIFF **
    params.preproc_dwi_run_denoising = true
```


**Well done !**

You now have a workflow with one `nf-neuro` subworkflow and your own `local` subworkflow
in your Nextflow pipeline! **Test it out !**

    <Tabs>
    <TabItem label="Check if it works">

    ```bash
    nextflow run main.nf --input data -profile docker
    ```

    </TabItem>
    <TabItem label="Expected output">
    ```bash
        N E X T F L O W   ~  version 24.10.4

        Launching `main.nf` [mighty_bose] DSL2 - revision: 7d89ad250c

        executor >  local (5)
        [6d/15e8f5] PREPROC_DIFF:DENOISING_MPPCA (sub-003_ses-01)    [100%] 1 of 1 ✔
        [18/41c27f] PREPROC_DIFF:RECONST_DTIMETRICS (sub-003_ses-01) [100%] 1 of 1 ✔
        [de/b69a00] PREPROC_T1:DENOISING_NLMEANS (sub-003_ses-01)    [100%] 1 of 1 ✔
        [e0/adaf76] PREPROC_T1:BETCROP_SYNTHBET (sub-003_ses-01)     [100%] 1 of 1 ✔
        [8f/41d4e5] STATS_METRICSINROI (sub-003_ses-01)              [100%] 1 of 1 ✔
        Completed at: 16-Mar-2025 20:00:54
        Duration    : 2m 4s
        CPU hours   : (a few seconds)
        Succeeded   : 5
    ```

    </TabItem>
    <TabItem label="Expected main.nf">
    ```nextflow
        #!/usr/bin/env nextflow

        include { PREPROC_T1 } from './subworkflows/nf-neuro/preproc_t1/main'
        include { STATS_METRICSINROI } from './modules/local/stats/metricsinrois/main'
        include { PREPROC_DIFF } from './subworkflows/local/preproc_diff/main'


        workflow get_data {
            main:
                if ( !params.input ) {
                    log.info "You must provide an input directory containing all images using:"
                    log.info ""
                    log.info "    --input=/path/to/[input]   Input directory containing your subjects"
                    log.info "                        |"
                    log.info "                        ├-- S1"
                    log.info "                        |    ├-- *dwi.nii.gz"
                    log.info "                        |    ├-- *dwi.bval"
                    log.info "                        |    ├-- *dwi.bvec"
                    log.info "                        |    └-- *t1.nii.gz"
                    log.info "                        └-- S2"
                    log.info "                             ├-- *dwi.nii.gz"
                    log.info "                             ├-- *bval"
                    log.info "                             ├-- *bvec"
                    log.info "                             └-- *t1.nii.gz"
                    log.info ""
                    error "Please resubmit your command with the previous file structure."
                }

                input = file(params.input)
                // ** Loading DWI files. ** //
                dwi_channel = Channel.fromFilePairs("$input/**/**/dwi/*dwi.{nii.gz,bval,bvec}", size: 3, flat: true)
                    { it.parent.parent.parent.name + "_" + it.parent.parent.name} // Set the subject filename as subjectID + '_' + session.
                    .map{ sid, bvals, bvecs, dwi -> [ [id: sid], dwi, bvals, bvecs ] } // Reordering the inputs.
                // ** Loading T1 file. ** //
                t1_channel = Channel.fromFilePairs("$input/**/**/anat/*T1w.nii.gz", size: 1, flat: true)
                    { it.parent.parent.parent.name + "_" + it.parent.parent.name } // Set the subject filename as subjectID + '_' + session.
                    .map{ sid, t1 -> [ [id: sid], t1 ] }
            emit:
                dwi = dwi_channel 
                anat = t1_channel
        }

        workflow {
            inputs = get_data()

            //Processing DWI
            PREPROC_DIFF( inputs.dwi )

            // Preprocessing T1 images
            //inputs.anat.view()

            PREPROC_T1(
                inputs.anat,
                Channel.empty(),
                Channel.empty(),
                Channel.empty(),
                Channel.empty(),
                Channel.empty(),
                Channel.empty()
            )

            // Extract FA value 
            input_extract_metric = PREPROC_T1.out.image_bet
                    .join(PREPROC_DIFF.out.fa)
                    .map{ it }
            
            STATS_METRICSINROI( input_extract_metric )

        }
    ```

    </TabItem>
    <TabItem label="Expected nextflow.config">
    ```nextflow
        profiles {
            docker {
                docker.enabled          = true
                conda.enabled           = false
                singularity.enabled     = false
                podman.enabled          = false
                shifter.enabled         = false
                charliecloud.enabled    = false
                apptainer.enabled       = false
                docker.runOptions       = '-u $(id -u):$(id -g)'
            }
        }

        manifest {
            name            = 'scilus/nf-neuro-tutorial'
            description     = """nf-neuro-tutorial is a Nextflow pipeline for processing neuroimaging data."""
            version         = '0.1dev'
        }

        params.input      = false
        params.output     = 'result'

        // ** Subworflow PREPROC_DIFF **
        params.preproc_dwi_run_denoising = true

        // ** Subworkflow PREPROC T1 **
        params.preproc_t1_run_denoising = true
        params.preproc_t1_run_N4 = false
        params.preproc_t1_run_resampling = false
        params.preproc_t1_run_ants_bet = false
        params.preproc_t1_run_synthbet = true
        params.preproc_t1_run_crop = false


        process {

            publishDir = { "${params.output}/$meta.id/${task.process.replaceAll(':', '-')}" }

            withName: "DENOISING_MPPCA" {
                ext.extent = 3
            }

            withName: "BETCROP_SYNTHBET" {
                memory = "4G"
                ext.nocsf = false
            }

            withName: "RECONST_DTIMETRICS" {
                ext.ad = false
                ext.evecs = false
                ext.evals = false
                ext.fa = true
                ext.ga = false
                ext.rgb = false
                ext.md = true
                ext.mode = false
                ext.norm = false
                ext.rd = false
                ext.tensor = false
                ext.nonphysical = false
                ext.pulsation = false
                ext.residual = false
                ext.b0_thr_extract_b0 = 10
                ext.dwi_shell_tolerance = 50
                ext.max_dti_shell_value = 1200
                ext.run_qc = false
            }

            withName: "STATS_METRICSINROI" {
                ext.bin = true
                ext.normalize_weights = false
            }
        }
    ```
    </TabItem>
    </Tabs>




## Step 8 : Reorganize output in result folder ( BIDS like format - Optional )

In this step, we will guide you through the process of configuring the output 
of your Nextflow pipeline to follow a BIDS-like structure. 

### Example for one module

We will integrate specific configurations, including the use of `publishDir`, `saveAs`, and `path` 
in the `nextflow.config` file to handle the output of the process `BETCROP_SYNTHBET`.
(This configuration **must be applied to each module** in your pipeline to ensure all outputs are properly organized.)


Here is an example of the structure output :

<Tabs>
<TabItem label="Example of BIDS-like output format">

```nextflow

    // Add those parameters after the params.output

    // Publish BIDS-like configuration
    params.lean_output = true
    params.publish_dir_mode = 'copy'

    // In process {} part

    withName: "BETCROP_SYNTHBET" {
        memory = "4G"
        ext.nocsf = false
        publishDir = [
            mode: params.publish_dir_mode,
            saveAs: {
                filename ->
                def ses = meta.session ? "_${meta.session}" : ""
                if ( filename.contains("bet_image.nii.gz") ) { "${meta.id}_${ses}_desc-t1_bet.nii.gz" }
                else if ( filename.contains("brain_mask.nii.gz") ) { "${meta.id}_${ses}_desc-t1_mask.nii.gz" }
                else if ( filename.contains("versions.yml") ) { null }
                else { params.lean_output ? null : filename }
            },
            path: { meta.session ? "${params.output}/${meta.id}/${meta.session}/anat/" : "${params.output}/${meta.id}/anat/" },
            enabled: params.lean_output ? false : true
        ]
    }
```

</TabItem>
<TabItem label="Let's break it down">

<Steps>
1. `publishDir` : Specify directory

    The `publishDir` directive in Nextflow specifies where the output files from a process 
    should be saved. To match the BIDS format, we need to use dynamic paths that follow the BIDS directory structure.

    ```nextflow
    /<directory>/<subject>/<session>/<datatype>/<file>
    ```

    Where:

    **subject** is the identifier for the participant.

    **session** is the identifier for the session (if applicable).

    **datatype** refers to the type of data (e.g., `anat`, `func`).

    **file** is the actual output file (e.g., T1-weighted MRI image, functional MRI data).

2. `mode` : Mode of publishing

    The `mode` of publishing is set by a parameter, allowing flexibility in how files are published (e.g., copy, symlink, etc.).
    Define here with `params.publish_dir_mode`.

3. `SaveAs` : Name convention.

    The `saveAs` function allows you to rename or reorganize output files as they are published. 
    This is particularly helpful when you need to ensure that your output files have BIDS-compliant filenames.

    It uses the following logic:

    `def ses = meta.session ? "_${meta.session}" : ""` : It **checks** if there's a session in the metadata and creates a session string accordingly.

    `if ( filename.contains("bet_image.nii.gz") ) { "${meta.id}_${ses}_desc-t1_bet.nii.gz" }` : For specific file types (bet_image.nii.gz and brain_mask.nii.gz), it **renames** them with a structured naming convention including metadata.

    `if ( filename.contains("versions.yml") ) { null }` : It **excludes the versions.yml** file from being published.

    For other files, it either publishes them **as-is** or **excludes** them based on the `params.lean_output` setting.

4. path: Directory structure

    This defines the directory structure for publishing outputs. 
    The subject and session might be derived from the filenames or passed as inputs.

    It includes the subject (`meta.id`), session (`meta.session`), and output (`params.output`).

    Using `meta.session ? "path_with_meta_session" : "path_without_meta_session"` if no session is provided, the path will omit the session and just use the subject ID.

5. enabled: 

    This enables or disables the publishing of outputs based on the `params.lean_output` parameter. 
    If lean_output is true, publishing is disable : `params.lean_output ? false : true`

</Steps>

This configuration allows for fine-grained control over how files are renamed, where they are stored, 
and whether they are published based on specific parameters such as lean_output.

</TabItem>
</Tabs>

Make sure to apply this structure to every process in your pipeline that produces output to ensure that all data is 
organized consistently, making it easier to integrate with other BIDS-compliant tools and workflows.Additionally, 
by defining the appropriate metadata and passing the required parameters, you can easily reorganize 
your output files and make them ready for further analysis.

### Run with BIDS-like format nextflow.config

Copy and paste this nextflow.config or write it yourself for each module and run your nextflow pipeline again.

```bash
nextflow run --input data -profile docker -resume
```

```nextflow
    profiles {
        docker {
            docker.enabled          = true
            conda.enabled           = false
            singularity.enabled     = false
            podman.enabled          = false
            shifter.enabled         = false
            charliecloud.enabled    = false
            apptainer.enabled       = false
            docker.runOptions       = '-u $(id -u):$(id -g)'
        }
    }

    manifest {
        name            = 'scilus/nf-neuro-tutorial'
        description     = """nf-neuro-tutorial is a Nextflow pipeline for processing neuroimaging data."""
        version         = '0.1dev'
    }

    params.input      = false
    params.output     = 'result'

    // Publish BIDS-like configuration
    params.lean_output = true
    params.publish_dir_mode = 'copy'

    // ** Subworflow PREPROC_DIFF **
    params.preproc_dwi_run_denoising = true

    // ** Subworkflow PREPROC T1 **
    params.preproc_t1_run_denoising = true
    params.preproc_t1_run_N4 = false
    params.preproc_t1_run_resampling = false
    params.preproc_t1_run_ants_bet = false
    params.preproc_t1_run_synthbet = true
    params.preproc_t1_run_crop = false


    process {

        //publishDir = { "${params.output}/$meta.id/${task.process.replaceAll(':', '-')}" }

        withName: "DENOISING_MPPCA" {
            ext.extent = 3
            publishDir = [
                mode: params.publish_dir_mode,
                saveAs: {
                    filename ->
                    def ses = meta.session ? "_${meta.session}" : ""
                    if ( filename.contains("denoised.nii.gz") ) { "${meta.id}_desc-denoised_dwi.nii.gz" }
                    else if ( filename.contains("versions.yml") ) { null }
                },
                path: { meta.session ? "${params.output}/${meta.id}/${meta.session}/dwi/" : "${params.output}/${meta.id}/dwi/" }
            ]
        }

        withName: "BETCROP_SYNTHBET" {
            memory = "4G"
            ext.nocsf = false
            publishDir = [
                mode: params.publish_dir_mode,
                saveAs: {
                    filename ->
                    def ses = meta.session ? "_${meta.session}" : ""
                    if ( filename.contains("bet_image.nii.gz") ) { "${meta.id}_${ses}_desc-t1_bet.nii.gz" }
                    else if ( filename.contains("brain_mask.nii.gz") ) { "${meta.id}_${ses}_desc-t1_mask.nii.gz" }
                    else if ( filename.contains("versions.yml") ) { null }
                    else { params.lean_output ? null : filename }
                },
                path: { meta.session ? "${params.output}/${meta.id}/${meta.session}/anat/" : "${params.output}/${meta.id}/anat/" },
                enabled: params.lean_output ? false : true
            ]
        }

        withName: "RECONST_DTIMETRICS" {
            ext.ad = false
            ext.evecs = false
            ext.evals = false
            ext.fa = true
            ext.ga = false
            ext.rgb = false
            ext.md = true
            ext.mode = false
            ext.norm = false
            ext.rd = false
            ext.tensor = false
            ext.nonphysical = false
            ext.pulsation = false
            ext.residual = false
            ext.b0_thr_extract_b0 = 10
            ext.dwi_shell_tolerance = 50
            ext.max_dti_shell_value = 1200
            ext.run_qc = false
            publishDir = [
                mode: params.publish_dir_mode,
                saveAs: {
                    filename ->
                    def ses = meta.session ? "_${meta.session}" : ""
                    if ( filename.contains("md.nii.gz") ) { "${meta.id}_${ses}_desc-md.nii.gz" }
                    else if ( filename.contains("fa.nii.gz") ) { "${meta.id}_${ses}_desc-fa.nii.gz" }
                    else if ( filename.contains("versions.yml") ) { null }
                    else { params.lean_output ? null : filename }
                },
                path: { meta.session ? "${params.output}/${meta.id}/${meta.session}/dwi/" : "${params.output}/${meta.id}/dwi/" }
            ]
        }

        // Here is an example where you want to store output with two different datatypes (stats + dwi)
        withName: "STATS_METRICSINROI" {
            ext.bin = true
            ext.normalize_weights = false
            publishDir = [
            [
                mode: params.publish_dir_mode,
                saveAs: {
                    filename ->
                    def ses = meta.session ? "_${meta.session}" : ""
                    if ( filename.contains("stats.json") ) { "${meta.id}_${ses}_desc-dti_stats.json" }
                    else { params.lean_output ? null : filename }
                },
                path: { meta.session ? "${params.output}/${meta.id}/${meta.session}/stats/" : "${params.output}/${meta.id}/stats/" }
            ],
            [
                mode: params.publish_dir_mode,
                saveAs: {
                    filename ->
                    def ses = meta.session ? "_${meta.session}" : ""
                    if ( filename.contains("map_csf.nii.gz") ) { "${meta.id}_${ses}_desc-t1_map_csf.nii.gz" }
                    else if ( filename.contains("map_wm.nii.gz") ) { "${meta.id}_${ses}_desc-t1_map_wm.nii.gz" }
                    else if ( filename.contains("map_gm.nii.gz") ) { "${meta.id}_${ses}_desc-t1_map_gm.nii.gz" }
                    else if ( filename.contains("mask_csf.nii.gz") ) { "${meta.id}_${ses}_desc-t1_mask_csf.nii.gz" }
                    else if ( filename.contains("mask_wm.nii.gz") ) { "${meta.id}_${ses}_desc-t1_mask_wm.nii.gz" }
                    else if ( filename.contains("mask_gm.nii.gz") ) { "${meta.id}_${ses}_desc-t1_mask_gm.nii.gz" }
                    else { params.lean_output ? null : filename }
                },
                path: { meta.session ? "${params.output}/${meta.id}/${meta.session}/anat/" : "${params.output}/${meta.id}/anat/" }
            ]
            ]
        }
    }
```

```bash
nextflow run --input data -profile docker -resume
```

:::note
Note that once the pipeline has run, you can experiment with different `publishDir` options by using the 
resume feature and changing the `params.output` parameter to `result_2` or another directory. 
Nextflow will simply copy the images from the work directory to the new output folder, following the output definitions you have set.
:::



:::caution
Do cannot set both a `global` publishDir (`publishDir = { "${params.output}/$meta.id/${task.process.replaceAll(':', '-')}" }`)
and a publishDir for each individual module at the same time. 
(Is it useful ???) 
:::


## Dataset 

You can find example **input data** [here](https://openneuro.org/datasets/ds004513/versions/1.0.4). Take
note that the dataset is very large, consider using a **data management system** like datalab
to download a single subject. You are also free to use any of your own data, as long
as they respect the directory structure defined [above](#create-a-prototype-pipeline).
:::
